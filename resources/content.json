{"pages":[{"title":"About","date":"2023-04-06T05:25:31.505Z","path":"about/index.html","text":""},{"title":"Tags","date":"2023-04-06T05:25:31.506Z","path":"tags/index.html","text":""},{"title":"Categories","date":"2023-04-06T05:25:31.506Z","path":"categories/index.html","text":""}],"posts":[{"title":"C++11中的负数取模问题","date":"2023-04-06T05:29:22.000Z","path":"wiki/C-11中的负数取模问题/","text":"今天在做1017. 负二进制转换 - 力扣（Leetcode）的时候涉及到了负数取模问题，逼迫我对这个知识点进行了学习。 题目描述如下： 给你一个整数 n ，以二进制字符串的形式返回该整数的 负二进制（base -2）表示。 注意，除非字符串就是 &quot;0&quot;，否则返回的字符串中不能含有前导零。 示例 1： 123输入：n = 2输出：&quot;110&quot;解释：(-2)^2 + (-2)^1 = 2 示例 2： 123输入：n = 3输出：&quot;111&quot;解释：(-2)^2 + (-2)^1 + (-2)^0 = 3 示例 3： 123输入：n = 4输出：&quot;100&quot;解释：(-2)^2 = 4 一种最简单的解法如下： 与转化为二进制没什么区别，都是除基取余，倒序排列。不过负二进制的余数可能有0，1，-1，而表示上不能有负数，所以在余数为-1时，要转化为1，同时商+1即可 1234567891011121314class Solution &#123;public: string baseNeg2(int n) &#123; string ans; while(n) &#123; int remain=n%(-2); ans+=&#x27;0&#x27;+abs(remain); n=remain&lt;0?n/(-2)+1:n/(-2); &#125; reverse(ans.begin(),ans.end()); return ans.empty()?&quot;0&quot;:ans; &#125;&#125;; 这里涉及到n%(-2)和n/(-2)的运算结果。C++ Primer第五版中是这么说的： C++ Primer中的这两段话可以归纳为如下两点： 在C++11中，除法运算m/n的商一律向零取整。此时，m/n、m/(-n)、(-m)/n、(-m)/(-n)这四个表达式的运算结果的绝对值均相等，运算结果的符号取决与被除数与除数是否同号，同号得正，异号得负。例如：21&#x2F;5&#x3D;4，21&#x2F;(-5)&#x3D;-4，-21&#x2F;5&#x3D;-4，-21&#x2F;(-5)&#x3D;4。换言之，商的绝对值乘以除数的绝对值一定不超过但最接近被除数的绝对值。 根据1可以推出，取模运算m%n的结果永远与m同号 回到LeetCode 1017这道题。当我们使用”除-2取余法“时，可能得到的余数为0、1、-1。由于最终结果为“-2的非负整数次幂相加”的形式，当余数为0或1时，可以直接作为结果中的一位；当余数为-1时，必须将其转换为非负数，方法为：让被除数多除一个-2，商加1，由于多除了一个-2，余数就需要减去一个-2，即余数-1加上2变为1。 本质上，解决这道题需要使用“正数除以负数，商向0取整；负数除以负数，商向无穷取整”的除法规则进行除-2取余，这样得到的所有余数都是正的，能够组合成“-2的非负整数次幂相加”的形式。然而由于C++11标准的除法一律向0取整，我们需要在每次得到负余数的时候多进行一次调整，以符合题目要求的除法规则。 为加深理解，再附上C++17中不同整数除以-2的运行结果：","tags":[{"name":"C++11","slug":"C-11","permalink":"https://starman-swa.github.io/tags/C-11/"},{"name":"进制转换","slug":"进制转换","permalink":"https://starman-swa.github.io/tags/%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2/"},{"name":"负数取模","slug":"负数取模","permalink":"https://starman-swa.github.io/tags/%E8%B4%9F%E6%95%B0%E5%8F%96%E6%A8%A1/"}],"categories":[{"name":"C++","slug":"C","permalink":"https://starman-swa.github.io/categories/C/"}]},{"title":"raft相关问题","date":"2023-03-29T11:13:47.000Z","path":"wiki/raft相关问题/","text":"Raft的一致性复制过程 客户端向leader发送请求 leader向自己的日志增加一条新entry，然后向所有的follower并行发送AppendEntries RPC来复制这条新entry。AppendEntries RPC可以一次性发送多条entry。 follower通过AppendEntries RPC中的prevLogIndex和prevLogTerm查找本地是否拥有这条entry的前一条entry，如果有，则删除其后所有冲突的entry，然后添加新entry，向leader发送success响应 当leader接收到来自过半数follower的success响应时，则将这条entry标记为commited，并在随后发送的AppendEntries RPC中将最新的leaderCommit发送给所有follower follower将自己的commitIndex更新为leaderCommit和本地最新index的最小值 所有服务器（包括leader、candidate和follower）定期将本地commitIndex对应的entry应用（apply）到本地状态机上 leader将entry应用到本地状态机后，响应客户端 当一个leader崩溃时，candidate当选leader的条件 candidate的日志至少要比过半数的followr更up-to-date，才可以获得过半数投票当选leader： 原因如下：当candidate满足这个条件是，它会包含所有已提交的entry： up-to-date的比较规则：先比较term，term相同再比较index 在一致性复制的不同阶段leader崩溃时，Raft分别如何处理？数据到达leader，但未复制到大多数follower 这条entry还没有被提交，剩余的节点会选出一个包含所有已提交日志的leader 当leader包含这条未提交的entry时，会对其进行间接提交 如果客户端还在原有的崩溃节点等待，当崩溃节点恢复时，会接收到新leader提交的这条entry，并应用到状态机，从而响应客户端 如果客户端向新的leader再次发送了这条请求，由于请求中含有客户端指定的唯一ID，尽管Raft提交了两条重复的请求，但只会向状态机应用一次 由于这条指令被间接提交后会被应用到每个可用节点的server层，因此客户端必须重试。如果客户端不重试，则会有一条错误的指令被执行。也就是说，一旦用户在客户端发送了一条请求，则这条请求不能够被撤回。 简而言之，此时的一致性由客户端指定的唯一操作ID保证 数据到达leader，成功复制到大多数follower，但leader未接收到过半数的响应 同上 数据到达leader，成功接收到了过半数的follower响应，但未更新commitIndex 只要未apply，就不会响应客户端。由于commitIndex未更新，因此视为没有commit，同上 数据到达leader，成功复制并且更新了commitIndex，但未在本地apply且未将commitIndex发送给大多数follower 新leader没有更新commitIndex，视为未commit。本机未apply，未响应客户端。因此不会有问题，同上 数据到达leader，成功复制并且更新了commitIndex，已在本地apply，但未将commitIndex发送给大多数follower 新leader没有更新commitIndex，视为未commit，但新leader的日志中包含这条entry，会对其间接提交。 原本发送请求的客户端接收了正确的响应。间接提交后所有节点的server层也能够正确执行这条指令。 数据到达leader，成功复制并且更新了commitIndex，未在本地apply，但已将commitIndex发送给大多数follower 新leader会apply这条指令。当客户端在新leader重试时，通过操作ID可以发现这条指令已经被执行了，直接返回success。如果客户端还在原leader等待，当原leader重启时也会apply这条指令并响应客户端 网络分区问题 假设小分区和大分区均存在leader，均可以接收客户端请求。小分区当中的entry，由于无法append到大多数，因此永远不会被commit；大分区当中的所有entry会被commit和apply。相应地，大分区的客户端请求可以被正确执行，而小分区的客户端请求会一直超时重试。 当小分区与大分区合并时，term更高的那个leader会成为整个集群的leader，其日志被复制到整个集群。 大分区的leader一定是term更高的，因为网络分区后，小分区中的票数不足，无法选举产生term更大的leader。所以新leader一定是大分区的leader，不会出现大分区的日志被小分区覆盖，导致已执行的客户端请求丢失的情况。 当分区合并后，小分区的leader变为follower，那些一直在超时重试的请求会返回失败。 CAP理论 在多节点系统当中，CAP三个性质只能同时满足两个 Consistence一致性：数据在多个副本之间保持一致的特性 Availability可用性：服务一直可用（但是不保证获取的数据为最新数据） Network Partitioning分区容错性：网络分区故障时仍然能对外提供满足一致性和可用性的服务，除非整个网络都发生了故障 raft的网络分区满足了AP特性：当网络分区时，如果要保证服务可用性，则副本之间有可能存在不一致。反之，如果对于副本的一致性有要求，例如金融系统，在网络分区情况下服务是不可用的，必须等到网络分区恢复。 Raft与一致性 有一种说法是，raft与一致性无关，raft只实现了共识，一致性针对的是服务，取决于上层应用。然而我认为一致性是服务和raft共同保证的。我的6.824 KV数据库的强一致性由服务层的唯一操作ID和raft层对读操作的共识共同实现。 如果只考虑raft，那么raft也必须为强一致性提供保证，即避免脏读。一种方法是我的读操作共识方法，另一种方法见下一小节。 一致性类型 最终一致性：写入过程中，客户端可能读到旧值，也可能读到新值 线性一致性（强一致）：当其中一个客户端读到了新的数据，所有的客户端都立即能够获取新数据 我的raft实现对于读请求必须达成共识，因此实现了强一致性。因为读请求之前的写请求对应的entry都被commit了，杜绝了“在写的过程中读”这回事 如果不想为读操作添加entry，应该怎么避免脏读 我的KV数据库实现为所有的读操作添加entry，等到该entry达成共识时才响应客户端，会带来较高的延迟 如果不为读操作添加entry，在不引入其他额外措施的情况下会发生脏读（论文第8节最后一段）：客户端读到了旧leader的值，而这个值已经被新leader修改了，但是由于网络分区等原因，旧leader还没有意识到他已经不是leader了。 为了防止脏读，需要引入下列两个措施： leader必须拥有之前所有被提交的日志，leader完整性可以保证leader最终会拥有所有已提交的日志，但在任期刚开始时可能还没拥有。此时需要发送一个no-op的空entry，以强制提交leader拥有的之前任期未被提交的日志 leader在响应读请求之前必须确保它仍然是leader，可以通过发送心跳，接收大多数节点的响应来检查 为什么需要提交no-op 如果leader在其任期开始时拥有之前任期的未被提交的日志，那么这条日志最终会被提交，然而leader在此时向客户端返回的是这条日志未提交的状态，产生了脏读 提交no-op可以强制提交这条日志，使leader更新到最新的状态 在我的6.824 KV数据库实现当中，由于采用了读共识，因此不需要提交no-op 为什么leader不能直接提交之前任期的entry 论文中的Figure 8进行了解释： 简而言之，leader只能在提交本任期日志的过程中，通过日志匹配规则“间接提交”之前任期的日志。如果直接提交之前任期的日志，则这条日志有可能被覆盖。 图中方框中的数字表示日志的任期，带黑框框的节点为leader。并且需要注意每个leader的任期：(c)中的S1为term&#x3D;4，(d)中的S5为term&#x3D;5 如果允许leader直接提交之前任期的entry，则第一步：(c)中S1向大多数节点复制并提交了term&#x3D;2的日志，然后崩溃了。第二步：(d)中S5的日志比大多数节点都要up-to-date，被成功选为leader，然后用自己的蓝色日志覆盖了黄色日志。 如果不允许直接提交，则第一步：(c)提交了term&#x3D;4的红色日志，并且间接提交了term&#x3D;2的黄色日志，变为(e)。此时，S5的日志没有比大多数节点up-to-date，无法被选为leader。 Raft试题 Raft 作者亲自出的 Raft 面试题！（含答案） - 掘金 (juejin.cn) 1问题 下面的每张图都显示了一台 Raft 服务器上可能存储的日志（日志内容未显示，只显示日志的 index 和任期号）。考虑每份日志都是独立的，下面的日志可能发生在 Raft 中吗？如果不能，请解释原因。 a： b： c： d： 解答 a：不可能，一旦服务器接收到term&#x3D;3的日志，会拒绝所有term&lt;3的请求，不可能再添加term&#x3D;2的日志 b：可能，日志的term号单调递增，一个term可能有多个日志 c：可能，一个term并不一定有新的日志 d：不可能，服务器在将一个entry附加到日志当中的时候，会保证前一个entry与leader匹配，因此不可能在某一个旧的index上有缺失的entry 2问题 下图显示了一个 5 台服务器集群中的日志（日志内容未显示）。哪些日志记录可以安全地应用到状态机？请解释你的答案。 解答 index&#x3D;1、2、3、4、5。因为这些日志被复制到了大多数（3个以上）节点 除此之外，我们还要考虑哪些日志会被新的leader截断 首先考虑哪些节点可以成为leader。根据up-to-date的规则，先比较term，再比较index，因此S2、S5都有可能成为leader。因为S2比S3、S4、S5更up-to-date，S5比S3、S4更up-to-date。当S2或S5成为leader时，index&gt;&#x3D;3的日志有可能被截断。因此，可以被安全应用的日志只有Index&#x3D;1、2 3问题 考虑下图，它显示了一个 6 台服务器集群中的日志，此时刚刚选出任期 7 的新 Leader（日志内容未显示，只显示日志的 index 和任期号）。对于图中每一个 Follower，给定的日志是否可能在一个正常运行的 Raft 系统中存在？如果是，请描述该情况如何发生的；如果不是，解释为什么。 解答 (a)：不可能，当前leader有3个term为3的日志，而term为3的leader将日志发送给(a)时会把之前term为2的日志截断 (b)：不可能，因为term为5的日志之前的日志与现leader矛盾，原因同(a) (c)：可能，这个节点与term为6的leader在同一个分区。这个节点可能是term为6的leader，并且在一个单独的分区 (d)：不可能，term号不可能递减 (e)：可能，term为1的leader向该节点多发送了4个entry，但与现leader不在一个网络分区，然后崩溃了。这个节点可能是term为1的leader，并且在一个单独的分区 4问题 假设硬件或软件错误破坏了 Leader 为某个特定 Follower 存储的 nextIndex 值。这是否会影响系统的安全？请简要解释你的答案。 解答 不会影响，因为有prevLogIndex和prevLogTerm来匹配follower和leader中相同的entry。nextIndex的变动不会影响匹配的正确性，只要匹配失败，nextIndex就会继续减小，直至成功。极端情况下，当nextIndex减小到0的时候，leader也能够将整个日志发送给follower 5问题 假设你实现了 Raft，并将它部署在同一个数据中心的所有服务器上。现在假设你要将系统部署到分布在世界各地的不同数据中心的每台服务器，与单数据中心版本相比，多数据中心的 Raft 需要做哪些更改？为什么？ 解答 选举超时和心跳超时需要延长时间，否则会因为网络传输时间变长导致频繁的领导变更 6问题 每个 Follower 都在其磁盘上存储了 3 个信息：当前任期（currentTerm）、最近的投票（votedFor）、以及所有接受的日志记录（log[]）。 a. 假设 Follower 崩溃了，并且当它重启时，它最近的投票信息已丢失。该 Follower 重新加入集群是否安全（假设未对算法做任何修改）？解释一下你的答案。 b. 现在，假设崩溃期间 Follower 的日志被截断（truncated）了，日志丢失了最后的一些记录。该 Follower 重新加入集群是否安全（假设未对算法做任何修改）？解释一下你的答案。 解答 a：不安全，它有可能会在同一个term之内将票投给另外一个candidate，造成同一个term有两个leader，且这两个leader无法通过互相识别term来退位 b：安全，尽管这个follower会丢失一些已经被提交的日志，但是这些日志会被leader重新发送，最终它会重新拥有所有日志。并且由于这个follower的日志不是最up-to-date的，它也不可能通过成为新的leader来覆盖其他节点的日志。因此是安全的 b：不安全。截断会使得一个已提交的日志没有被存储在多数派上，此时，没有这条日志的节点就能够满足up-to-date条件而被选举为leader，并将其他follower中的这条日志都覆盖掉，导致一个index被提交了不同的值 7问题 如视频中所述，即使其它服务器认为 Leader 崩溃并选出了新的 Leader 后，（老的）Leader 依然可能继续运行。新的 Leader 将与集群中的多数派联系并更新它们的任期，因此，老的 Leader 将在与多数派中的任何一台服务器通信后立即下台。然而，在此期间，它也可以继续充当 Leader，并向尚未被新 Leader 联系到的 Follower 发出请求；此外，客户端可以继续向老的 Leader 发送请求。我们知道，在选举结束后，老的 Leader 不能提交（commit）任何新的日志记录，因为这样做需要联系选举多数派中的至少一台服务器。但是，老的 Leader 是否有可能执行一个成功 AppendEntries RPC，从而完成在选举开始前收到的旧日志记录的提交？如果可以，请解释这种情况是如何发生的，并讨论这是否会给 Raft 协议带来问题。如果不能发生这种情况，请说明原因。 解答 有可能，在新的leader选举出来之前，老的leader向多数派append了日志并提交，然后还没有来得及将新的commitIndex发送给follower就断开连接了。但是并不会给Raft协议带来问题，因为多数派当中只有日志最up-to-date的节点才可以被选为新的leader，因此，新leader一定包含这条被提交日志。 8问题 在配置变更过程中，如果当前 Leader 不在 C-new 中，一旦 C-new 的日志记录被提交，它就会下台。然而，这意味着有一段时间，Leader 不属于它所领导的集群（Leader 上存储的当前配置条目是 C-new，C-new 不包括 Leader）。假设修改协议，如果 C-new 不包含 Leader，则使 Leader 在其日志存储了 C-new 时就立即下台。这种方法可能发生的最坏情况是什么？ 解答 成员变更还没看，挖坑待填 其他问题为什么follower需要随机超时 为了防止多个follower同时变为candidate，造成split vote","tags":[{"name":"Raft","slug":"Raft","permalink":"https://starman-swa.github.io/tags/Raft/"}],"categories":[{"name":"分布式","slug":"分布式","permalink":"https://starman-swa.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"bzip2相关论文阅读笔记","date":"2023-03-21T14:05:52.000Z","path":"wiki/bzip2相关论文阅读笔记/","text":"Parallel Data Compression With Bzip2（分块压缩）压缩算法的分类 字典算法 LZ77（ZIP、GZIP） LZW（自适应） 并行研究 基于统计的算法 建模阶段-&gt;编码阶段 基本建模技术 符号频率 符号上下文 符号排名 算术编码器：PPM部分匹配预测 当前（2004）文本数据的最佳无损压缩算法 有限上下文统计建模技术 使用输入流的前一个字节来预测下一个字节 Burrows-Wheeler Transform概念 块排序、无损数据压缩算法，对输入块执行可逆变换 不执行任何压缩，但以某种方式修改数据，使其易于使用二级算法进行压缩 变换后的块包含与原始块相同的字符，但是形式易于压缩，例如相同字符分组在一起 原理（逆过程见Parallel algorithms for Burrows–Wheeler compression and decompression） 过程 源字符串S，包含N个字符 将S旋转（循环移位）N次，将旋转过程中生成的N个中间串进行字典排序 提取这N个串的最后一个字符，组合成串L I为源串S在排序后的串列表当中的索引 选择分块大小，至少2KB。增大块大小可以增强有效性 视为三个阶段 排序阶段 “Move-To-Front”阶段 压缩阶段 性能 内存消耗：9B内存&#x2F;1B数据+700KB常量 Move-To-Front编码器的选取影响压缩率：不同的排序顺序和源字母表的顺序 最佳性能：O(logn&#x2F;n)，优于LZ77、LZ78 应用 BZIP2：BTW+哈夫曼编码 压缩率优于基于字典算法的LZ77&#x2F;LZ78 在基于统计算法的PPM中，压缩率接近，但快很多 并行BWT 并行排序 分块BWT 结合上述两种方法 性能取决于处理器数量，需要进行测试 并行BZIP2（PBZIP2） pthread 分块 块在内存中以生产者&#x2F;消费者模型、FIFO管理 每个处理器读取块，执行BWT，然后释放内存 实验 随着处理器数量的上升，pbzip2压缩时间减小。减小到大概12个处理器就增长缓慢了。 Practical Speculative Parallelization of Variable-Length Decompression Algorithms（分块解压）解决的问题 如果压缩时采取块级并行，那么解压的时候，在完成对一个块的解压之前，无法确定这个块的边界 相关工作的解决办法： 在压缩块的末尾插入填充位，或者加入提示：只适用于修改后的压缩器 Klein和Wiseman利用Huffman编码的自同步特性：只适用于静态Huffman编码 块边界位置在一个输入之内或跨不同输入的相关性几乎为0，因此难以应用domain-unaware value prediction algorithms 提出SDM：一个有效预测区块边界的新算法，和能够实现高效区块级并行解压的运行时系统 思考：运行时系统能否被很好应用于移动端？可以，因为华为手表的升级程序是官方定制的。本文的实验是在嵌入式平台上做的 不需要修改压缩器 动机变长解压算法 即使压缩时定长分块，生成的每个块大小也不一样 解压时存在的依赖： 基于值预测的推测并行化 三种方法均无效： pos变量在一段时间内或者不同的输入之间构成几乎0的相关性，使得值预测无效 在一个块末尾计算pos的复杂性与解压整个块的复杂性相当，使得提取预测器函数开销太大 复杂的依赖模式和有限的程序分析能力使得automatic distiller也无效 目标：三个部件 自定义值预测器：以高置信度和低开销确定每个压缩块的起点 运行时错误预测检测和恢复机制 易于使用的并行化API：将现有的变长解压算法转化为基于值预测的推测并行代码 块边界预测算法第一种：基于部分解压 不适用于bzip2，略 第二种：基于模式匹配 bzip2包含一个48比特的魔数头，用于标识一个新的被压缩块的开始；并且不存在块间依赖。采用模式匹配 SDM执行模型SDM三阶段流水线 三种进程：扫描器、解压器、合并器 主进程创建并配置每个阶段 主进程本身作为合并器 默认：解压进程数量&#x3D;&#x3D;可用核心数量 在拥有大量可用核心的多核嵌入式平台当中，使用集中式提交模型（一个合并器） 解压-合并通信可能成为性能瓶颈 由于上下文切换和内存空间开销，核心数较少的平台无法从额外的进程受益，需要使用分布式提交模型 将解压器和合并器融合 如何顺序提交：定义一个提交令牌在进程间传递。一个块解压后在本地缓存，等待收到解压令牌后才进行提交 错误预测检测和恢复 由合并器负责：将从扫描器收到的预测值与解压器收到的实际值进行对比 如果检测到一个错误预测，所有的扫描器和解压器都被停止，程序的其余部分顺序执行 SDM API 略 实验 错误恢复的性能：对于bzip2，如果误判发生在输入文件的开头附近会造成轻微的性能下降；但是在大多数情况下都比顺序执行要快 Parallel algorithms for Burrows–Wheeler compression and decompression（块内压缩和解压）贡献 第一个应用于BW压缩和解压缩问题的PRAM算法 相比Parallel Data Compression With Bzip2，解决了整个输入的BWT问题，而不是分块 本方法与分块方法正交，因此还可以在单个块上叠加应用本方法 预备知识BST正过程 见Parallel Data Compression With Bzip2 逆过程（IBST） 定义SBST为BST正过程生成的串，M为BST正过程排序后的矩阵（显然M为方阵）。显然SBST为M的最后一列 需要一个符号表示字符串末尾，且这个符号的字典序最小。对于英文字符串，可以取ASCII序在英文字母之前的”$“。在Parallel Data Compression With Bzip2这篇论文当中则是用一个数组记录 迭代法生成M的每一列，迭代N次后，取M的第一行即为原来的S 为了生成M的第一列，将*SBST*进行稳定排序。 为了生成M的前两列，执行下列两个步骤： 将*SBST*插入到第一列的左边 对M的前两列进行下列定义的排序： 如果两行的第一个字符不同，则根据第一个字符排序 如果两行的第一个字符相同，不动 重复2直到生成M O(N)复杂度方法 图示思路：将M中的所有*$写出来；然后旋转每一行，使得$位于最后一列；此时，从左往右读就是源串S* 伪代码：有点难读懂，先略过 MTF正过程 给定一个字符，MTF将每个字符替换为：该字符本次出现与上次出现之间，不同字符的个数。为了保证该定义有效，规定字母表在*SBST*之前以某种顺序出现。 定义*Li为SBST*的前i个字符中，每一个不同字符以其最后一次出现的位置倒序生成的列表，且考虑上述假定的前缀。 伪代码： L :&#x3D; L0（即假定前缀的倒序） for i :&#x3D; 0 to n - 1 do j :&#x3D; SBST[i]在L中的索引 SMTF[i] :&#x3D; j 将L[j]移动到L首部 目的：由于BST保证了同个字符的出现位置相近，MTF生成的是小整数序列，即小整数出现频率很高。因此该序列适合于进行Huffman编码。 逆过程 伪代码： L :&#x3D; L0 for i :&#x3D; 0 to n - 1 do j :&#x3D; SMTF[i] SBST :&#x3D; L[j] 将L[j]移动到L首部 Huffman编码正过程 伪代码： 把字母表中的每个字符在SMTF中出现的次数进行统计，生成频率表F 使用频率表F构造码表T。对于任意两个字符a、b，如果F(a) &lt; F(b)，则|T(a)|&gt;&#x3D;|T(b)| 将SMTF中的每个字符用T中对应的码字代替，生成SBW。SBW即为整个压缩算法的输出 思考： 源串中一个字符需要一个字节来存储；Huffman编码后字符由几个0、1比特表示，只需要几个位来存储。如果Huffman的平均字长小于8，则源文件体积能够减小。 逆过程 显而易见。参考解压的并行一章 压缩的并行BST 构建后缀树 性能： Sahinalp and Vishkin的算法：O(log2n)时间，O(n)工作，O(n2)空间 可以将空间复杂度降到O(n1+ε)，当时间增加1&#x2F;ε倍 Hariharan的算法：O(log4n)时间，O(n)工作，O(n)空间 DFS遍历后缀树，生成后缀数组SA 欧拉旅行技术 相同复杂度界限 按照如下公式生成*SBST*：SBST[i]&#x3D;S[(SA[i]-1)mod n], 0&lt;&#x3D;i&lt;n 性能：O(1)时间，O(n)工作 MTF编码 定义 MTF(X)：同Li，只不过Li针对的是输入串的前缀，MTF(X)进行了扩展，针对任意子串X x⊕y： 把在y中出现过的字符从x中移除生成一个列表，然后把这个列表拼接到y的后面 注解：y不动，x中单独出现的部分拼在y后面 观察 MTF(c)&#x3D;(c) MTF(XY)&#x3D;MTF(X)⊕MTF(y) 目标：计算所有Li，即计算SBST（考虑假定前缀）所有前缀的MTF 步骤： 将*SBST*的每个元素看成初始的列表，从下往上，在一棵平衡二叉树中用⊕运算符两两合并列表，直到根节点 从上到下，计算每个节点的⊕运算前缀和（从根的最左叶子节点到当前子树的最右叶子节点）。叶子节点的前缀和即为Li 性能： 时间复杂度：O(|Σ|logn)时间，O(|Σ|n)工作 空间复杂度：n|Σ| 权衡空间和时间的方法（划分粒度）：选取一个k&lt;n，只排序*L0、Lk、L2k*、……。此时空间降低k倍，时间相应增加k倍 Huffman编码看了，但暂时不关心，没记录 解压的并行Huffman解码 难点：由于Huffman码字是变长的，需要选定*SBW*的分割位置 定义l为最长码字的长度。不失一般性，假定|SBW|能够被l整除，我们要把SBW分割为若干个长度为l的切分。目标是选定每个切分的开始位置 计算开始位置需要两个步骤：初始化-&gt;前缀和计算 初始化阶段 从SBW中的每个位SBWi开始执行解码（解码一个码字）。对于每个i，获得一个停止解码的位置j。记为i-&gt;j 前缀和计算阶段 对于形如a-&gt;b、b-&gt;c的映射，将他们合并为a-&gt;c 合并后，0指向的所有位置都是开始位置，保存到集合V中 实际解码阶段如下： 部署n&#x2F;l个处理器，每个处理器指定集合V中一个不同的开始位置，并行执行哈夫曼解码，直到到达下一个开始位置。解码后先不写到内存。O(l)时间，O(n)工作 使用前缀和为每个处理器在SMTF的输出分配空间。**O(log n)时间，O(n)工作 重复步骤1，将输出写到*SMTF*。O(l)时间，O(n)工作 实际解码阶段：O(logn+l)时间，O(n)工作 思考：这么细的划分粒度值得吗？partition的块数太多了，是否可以不要分那么多 MTF解码 与编码类型 性能相同：O(|Σ|logn)时间，O(|Σ|n)工作 IBST 涉及Cole and Vishkin的整数排序算法 性能：O(|Σ|logn)时间，O(|Σ|n)工作 性能：O(|Σ|logn)时间，O(|Σ|n)工作 实验 这篇文章没有做实验 实验在另一篇文章Empirical Speedup Study of Truly Parallel Data Compression Empirical Speedup Study of Truly Parallel Data Compression（块内压缩和解压）实验 在XML计算平台的64-TCU FPGA上运行时，解压性能总体上看甚至略微下降了；在模拟的1024-TCU上运行时有提升 思考：这个是在专用的并行计算平台上运行的结果，对移动端的参考价值？ Parallelizing Bzip2: A Case Study in Multicore Software Engineering（学生作品）简介 一个多核软件工程课程的最后三周，8名计算机科学专业的研究生2人一组进行比赛，对bzip2算法进行并行化 针对压缩 Team 1 发现细粒度的并行化不合适，需要大量努力重构代码 尝试用类重构，但最后ddl到了还是换回没有类的版本，整合了Bzip2SMP的一些并行化思想 Team 2（winner） 重构花了很长时间，最后一天才写并行 生产者-消费者模式+pthreads 流水线没时间写了 Team 3 master-worker方法 master程序向一个缓冲区填充块，worker程序从缓冲区中取出块来进行压缩 线程同步和文件顺序输出遇到困难 超时了 Team 4 用openmp，性能较差 大部分时间花在理解代码 Lessons Learned 并行化之前需要重构代码 增量并行化没有作用 例如用OpenMP在代码开头加pragma 研究关键路径行不通 例如用profile工具 顺序实现通常涉及设计选择，排除了并行化可能需要的自由度 因此，仅仅研究顺序实现是不够的，还需要研究规范 细粒度并行不是唯一选择 例如，关键路径上循环的并行化只产生很小的速度提升 寻找高层次并行化 例如，引入生产者-消费者模式或者master-worker模式 代码实现涉及的细节更多 试错是有风险的 并行化不是黑色艺术 Advice 并行时考虑多个层次 不然就会“一分钱一分货” 如果从0开始写顺序代码，要为并行化考虑 多练习 相关前置知识 自适应（动态）哈夫曼编码与解码过程_菜鸟的逆袭之路的博客-CSDN博客_动态哈夫曼编码 Parallel algorithms for Burrows–Wheeler compression and decompression中使用的Huffman编码是动态的，因为没有提到要存Huffman树 并行算法科普向 系列之二：前缀和，fork-join 和矩阵乘法 - 知乎 (zhihu.com) 值预测算法：见文章Value Prediction for Speculative Multithreaded Architectures Practical Speculative Parallelization of Variable-Length Decompression Algorithms中提到值预测算法不可用 值预测技术基于以下推测：在大量的时间内，值倾向于重复，或者遵循一个已知的模式。因此，如果使用恰当的机制，值可能能够被正确地预测。这些机制的基础是存储反映近期观察到的历史信息的表格 分类 基于指令的值预测器 基于追踪的值预测器 相关实现bwtzip bwtzip - nuwen.net 他是高度模块化的，或许可以帮助我后续的代码重构和实现 相关会议 Data Compression Conference：IEEE Xplore - Conference Table of Contents","tags":[{"name":"压缩","slug":"压缩","permalink":"https://starman-swa.github.io/tags/%E5%8E%8B%E7%BC%A9/"}],"categories":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://starman-swa.github.io/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"}]},{"title":"bsdiff相关论文阅读笔记","date":"2023-03-21T13:57:13.000Z","path":"wiki/bsdiff相关论文阅读笔记/","text":"基于play framework的APP托管平台的设计与实现（北京邮电大学 硕士论文 2018） bsdiff&#x2F;bspatch+Linux rsync 基于文件分块的大文件更新策略解决的问题 客户端使用bspatch进行解压时，内存消耗过大 客户端本地的旧文件可能不完整或者受损，而bspatch需要完整的源文件 频繁更新场景下，服务器需要多次进行bsdiff，消耗时间长；并且需要管理多个版本的差分包 基本思路 服务端 对新文件进行滚动校验，生成校验表 两个校验表 弱校验：速度快但冲突概率高，采用Adler-32 强校验：速度慢但冲突概率小，采用MD5 客户端 下载服务端的新文件校验表 对本地文件进行滚动校验（先弱校验，如命中再强校验） 如果两次校验的结果在新文件校验表中均命中，则将该块标记为匹配部分，指针后移一个块 如果未命中，则将该字节标记为不匹配，指针后移一个字节 从服务器下载未匹配的部分 将下载到的未匹配部分与本地的匹配部分进行合成 A Software Update Scheme by Airwaves for Automotive Equipment（2013 International Conference on Informatics, Electronics and Vision (ICIEV)）解决的问题 将bsdiff&#x2F;bspatch应用到汽车上会面临着几个问题： 内存限制 不稳定的电源供应 不稳定的无线电波传输 方法原地更新 原地更新的挑战：写冲突，即前面的编辑操作修改了后面的编辑操作所要引用的旧二进制的空间 bsdiff场景：preceding Copy &amp; Modify and New edit operations 性能 原空间复杂度：u+v+w+O(1) 新空间复杂度：max(u,v)+w+O(1) 原地更新相关文章[11] R. C. Burms and D. D. E. Long, “In-Place Reconstruction of DeltaCompressed File,” ACM Symp. on Principles of Distributed Computing,pp.267–275, Jul. 1998.[12] D. Shapira and J. A. Storer, “In Place Differential File Compression,”The Computer Journal Advance Access, Vol.48, pp.667–691, Aug. 2005.[13] Y.-C. Cho and J. W. Jeon, “In-Place Reconstructible Delta Compression Using Alleviated Greedy Matching Algorithm,” Proc. Int. Conf. onIndustrial Informatics (INDIN2008), pp.1596–1601, Jul. 2008. In-Place Reconstruction of Delta Compressed Files (PODC ‘98 CCF-B)解决的问题 当差量指令指示计算机从一个文件区域复制数据时，新的文件数据可能已经被写入 基本思路 基于图论 对差分文件进行后处理 对尝试读取已写入区域的指令进行检测 对这些指令进行排序，以减少冲突的出现 对于剩余的冲突，删除这些指令，改为显式添加（会增大差分文件的大小） 修改差分文件为可就地重建的，花费的时间比生成差分时间还要长 （Conclusion又说时间更短，矛盾） 过程：一个原地重建算法 定义copy指令为三元组*&lt;f,t,l&gt;* f：源串中的地址 t：目标串中的地址 l：复制长度 冲突检测 对于copy指令*&lt;fi,ti,li&gt;和&lt;fj,tj,lj&gt;*，i&lt;j，存在一个WR冲突，当：[ti,ti+li-1]∩[fj,fj+lj-1]≠{} 与add指令相关的潜在WR冲突可以通过把add放在所有copy的末尾来避免 这种冲突出现于add先写，copy后读 copy指令的自冲突问题：读与写的区间重叠 解决方法 当f&gt;&#x3D;t时，从左到右逐字节复制 当f&lt;t时，从右到左逐字节复制 三个方法： 将所有的add放到差分文件的末尾 将copy指令排序，以减少WR冲突 对于剩余的WR冲突，将对应的copy指令转为add指令，并且放到差分文件的末尾 生成无冲突的排列 将copy指令按照t进行排序 将所有的copy指令用顶点表示 如果顶点u的读区间与顶点v的写区间重合，则创建一条边u-&gt;v 执行增强版的拓扑排序 如果检测到环，移除一个顶点（转为add）以消除环 移除最佳顶点以减少压缩损失是一个NP难问题 两种策略： 常数时间策略：选择最容易移除的顶点 局部最小策略：遍历环，选择删除开销最小的顶点，即copy的长度最小的指令 将拓扑排序后的copy指令写入输出文件，再将add指令写入输出文件 实验 数据集：GNU工具、BSD操作系统 压缩损失： 局部最小策略：2.4% 常数时间策略：5.9% In Place Differential File Compression（DCC 03 CCF-B and The Computer Journal 05）基本思路 提出了IPSW算法 将窗口初始化为S，将其最大尺寸限制为max(|S|,|T|)来对T进行解压 速度快，压缩效果好 当S和T有合理程度的对齐时（即S和T的大量匹配以大致相同的相对顺序出现），IPSW最有效 这种对齐在很多应用中是典型现象 当S和T不对齐时，对S进行预处理 压缩文件之前有一个位标识该文件是否经过预处理 编码器用IPSW对T进行压缩，与对S的压缩进行对比 如果差别很大，则设置初始位，进行对齐预处理，在IPSW编码前增加一个移动列表 解码器先原地执行这些动作，再执行正常的IPSW解码 本文直接生成可原地构建的差分文件，而不是对差分文件进行可原地构建处理 本文同时实现了就地压缩和就地解压 原地移动子串（压缩前置知识） 定义源串S，目标串T 差分文件包含一些移动指令（对应S和T匹配的块）和一些压缩数据（对应不匹配的部分） 解压流程如下： 对于收到的每条移动指令，对T的子串就地执行移动 对于压缩数据，进行解压，然后填补移动后的空隙 步骤2可以应用任何无损压缩方法 定义s为S中一个即将被移动的子串，l为s的长度，x为原位置，y为目标位置 本文定义的”移动“并不是简单覆盖，例如：当s往右移动1个字符时，原本在s右边的那个字符要变到s左边，而不是被覆盖 就地移动子串的高效方法： 过程 不失一般性，令x&#x3D;0，假设向右移动 对0到y-1的字符，进行排列：i → (i + d) MOD y 执行排列的方法 标准方法：O(y)时间、y比特的标记位空间 一个理论方法：O(1)空间，但在实际应用中节省y比特的标记位空间并不重要 当S和T对齐的情况下，移动只需要简单的字符串拷贝： 两次扫描文件，首先从左到右复制移动到左边的块，再从右到左复制移动到右边的块 实际执行过程可以设置多个阈值，分步贪心查找匹配的窗口 原地滑动窗口（压缩、解压缩过程） 问题：给定一个长度为m的串S，一个长度为n的串T，以及字符插入、块删除、块移动和块复制的操作集，计算将S转化为T所需的最小操作数 即压缩过程如何生成最小的差分文件 是一个NP-完全问题 可以通过一个简单的从左到右的贪婪复制算法（全窗算法）近似到一个恒定的常数内 全窗编码算法：略 ISPW算法： 构建字符串ST 在一个滑动窗口max(m,n)内，从左到右贪心地寻找与接下来的子串匹配的子串（使用上一节最后一部分叙述的分步贪心查找方法） 使用ISPW算法进行压缩后，由于限制了匹配子串只能在大小为max(m,n)的滑动窗口内进行查找，因此解压时所占用的内存空间也是max(m,n) 移动预处理算法（MP）先不看 实验 IPSW的压缩率与bsdiff接近 针对部分文件（如sql和部分的gcc），即使不采取MP，IPSW的压缩率也能优于bsdiff 即使采取了MP，IPSW针对dll文件的压缩率表现也比较差，少部分较好 我的结论：用IPSW实现原地解压后导致的压缩率损失与具体的文件格式有关系 In-Place Reconstructible Delta Compression using Alleviated Greedy Matching Algorithm（INDIN 08）解决的问题 现有方案的问题 Burns and Long的方案将COPY指令替换为ADD指令，增加了差分文件的大小 Shapira的方案使用了原地滑动窗口算法，然而解码时移动字符串几乎需要O(m)时间，使得解码器变得更加复杂，不适合于嵌入式系统；并且预处理步骤还会增大差分文件的大小 本文解决了这两个问题，适合于小内存和低计算能力的嵌入式系统 前置知识 找匹配串的方法 最优的找匹配串方法：后缀树。但需要线性空间，不适用于大文件 另一种方法：哈希方法。如Karp-Rabin哈希，可以递推计算 贪心方法 创建一个哈希表，保存指纹对应的所有下标（以链表形式） 算法对fnew当前位置的串进行哈希，在哈希表中找到最长匹配的串 如果匹配失败，则fnew下标加1 伪代码如下，注意APPEND和SET的被操作数是前面的变量： 方法：缓解的贪婪匹配算法 选取避免WR冲突的字符串匹配，而不是最长匹配 现有的确定最佳匹配串的贪心算法有如下两个标准： 匹配串长度 距离当前位置的offset 本文增加了一个标准： 是否有WR冲突（这个标准是最重要的） 伪代码： 当一个匹配串在旧文件当中，且下标在当前编码位置之前，则代表会发生WR冲突。该匹配节点将被移除 遍历完链表后，在所有不会发生WR冲突的节点当中找最佳匹配串 实验 本文在zdelta上应用了本方法，与原始zdelta和Burn的方法进行对比 本文方法生成的差分文件大小略小于Burn的方法 由于差分文件更小，本文的解压内存占用也略小于Burn的方法 Dfinder—An efficient differencing algorithm for incremental programming of constrained IoT devices（IOT 22）贡献 本文提出了Dfinder 字节级 使用增强的后缀数组，可以有效产生小的差分文件 可以正向和反向检测共同片段，还可以使用新固件中已经被重建的部分 O(nlogn)时间，O(n)空间 提出Dfinder的一个模式，允许就地重建 物联网空中编程前置知识 物联网领域使用的操作系统，如ContikiOS[18]，是模块化系统，支持动态链接[19]和加载；因此，就OTAP而言，它们只需要接收新固件映像的修改部分，因为在接收时，动态链接器会重新链接映像并再次加载它。可能会出现大量的开销，因为除了修改的部分，新的符号和重定位表也需要传输。Elon[20]通过引入可替换部件的概念来解决这个问题，这些部件包括。(i) 可替换的代码，(ii) 可替换的数据，以及(iii) 系统跳转表。然而，一个缺点是，这些（组件）存储在节点的RAM中，随后在系统重置的情况下需要重新传输。 相关算法： Xdelta BSDiff RMTD DASA R3 JojoDiff DG 增强的后缀数组 增强的后缀数组&#x3D;后缀数组SA+辅助数组（LCP数组、𝛷-数组等） Dfinder使用divsufsort Dfinder 指令 COPY(Copy_typeX|X&#x3D;1,2,3,4)，取决于BMD所检测的匹配片段的类型 ADD，连续的ADD指令可以合并 过程 块移动检测器（BMD） 动态编程假设共同的子序列以相同顺序出现，且无法捕获重复子序列。因此，Tichy使用了块移动 S2: a Small Delta and Small Memory Differencing Algorithm for Reprogramming Resource-constrained IoT Devices（INFOCOM ‘21)摘要 现代IoT应用的固件大小逐渐增大，使得现有差分算法面临RAM的瓶颈 提出S2 减小内存占用的方法 基于拓扑排序的原地重建算法 流重建技术 减小差分文件大小的方法 基于预测的编码 解决的问题和方法 有限的RAM：现有方法需要把整个旧文件读入RAM 方法：基于拓扑排序的原地重建 有限的flash空间：现有方法需要把新文件写入不同空间 方法：流重建技术 进一步减小差分文件大小 方法：基于预测的编码 方法S2DIFF 拓扑排序：同Burn的算法 基于预测的编码： 原始的指令地址参数都用8个字节编码，以支持大文件 文章观察到ADD序列的参数t是单调增加的，COPY的参数在拓扑排序前也是单调增加的 因此，文章用预测模型对地址参数进行编码：给定一个要编码的COPY的t地址，文章用前几个t来预测它的值，然后用预测的误差对t进行2个字节的编码 采用移动平均（MA）模型，因为它能在资源有限的设备上进行有效传输和执行，并且有令人满意的准确度 用xz进行二次压缩 S2PATCH 流重建 逐指令解压，用预测算法恢复指令的地址参数，然后执行 实验 baseline： AOS：AliOS Things操作系统中默认的增量重编程算法 将新旧文件分割成64KB的片段，然后对每个片段执行bsdiff bsdiff：包含Burn的原地重建算法","tags":[{"name":"差量压缩","slug":"差量压缩","permalink":"https://starman-swa.github.io/tags/%E5%B7%AE%E9%87%8F%E5%8E%8B%E7%BC%A9/"}],"categories":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://starman-swa.github.io/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"}]},{"title":"easy_note源码阅读","date":"2023-02-01T13:51:56.000Z","path":"wiki/easy-note源码阅读/","text":"简介easy_note为一个hertz+kitex+gorm样例项目。 项目地址：biz-demo&#x2F;easy_note at main · cloudwego&#x2F;biz-demo (github.com) 相关资料Kitex官方文档：Kitex | CloudWeGo Hertz官方文档：Hertz | CloudWeGo Hertz with thrift样例项目：hertz-examples&#x2F;hz&#x2F;thrift at main · cloudwego&#x2F;hertz-examples (github.com) Gorm官方文档：GORM 指南 | GORM - The fantastic ORM library for Golang, aims to be developer friendly. 组成 easy_note包含三个服务： note：提供笔记的curd服务 user：提供用户的注册和登录服务 api：与上述两个服务通信，对客户端提供http访问服务 结构 cmd：三个服务的实现 idl：定义服务间的通信内容 kitex_gen：kitex自动生成的服务间通信代码 pkg：定义一些常量和配置信息 note服务 dal dal文件夹包含数据库处理函数。其中的db/init.go初始化gorm连接，db/note.go定义了用gorm进行数据库操作的几个函数，包含笔记的crud。外层的dal/init.go进行了简单封装。总而言之，dal包中基于gorm封装了note表的crud操作函数，也包含gorm的初始化函数。 上图为gorm的模型定义。gorm使用结构体名的蛇形复数作为表名，字段名的蛇形作为列名，结构体还需要包含一个gorm.Model，其中包含主键和修改时间信息。 因此，gorm使用结构体的名称和字段来确定要操作的表，不需要显式的建表操作。 kitex的代码构建流程在阅读note服务的kitex代码之前，先了解kitex的代码构建流程。 第一步：编写IDL文件 创建IDL文件，编写接口和服务。 使用kitex生成项目代码： 1$ kitex -module $(go module名) -service $(服务名) $(IDL文件名) 生成如下所示的代码结构： 12345678910111213141516171819.├── build.sh├── echo.thrift├── go.mod├── handler.go├── kitex.yaml├── kitex_gen│ └── api│ ├── echo│ │ ├── client.go│ │ ├── echo.go│ │ ├── invoker.go│ │ └── server.go│ ├── echo.go│ ├── k-consts.go│ └── k-echo.go├── main.go└── script └── bootstrap.sh build.sh是编译脚本 handler.go是编写服务处理的地方，kitex生成了服务处理函数的框架，供开发者填写 kitex_gen是kitex生成的代码，不需要修改 main.go是主函数，可根据具体业务来自定义初始化逻辑，如将服务注册到etcd服务发现中心 script/boostrap.sh是启动服务的脚本，在编译后的output文件夹也会生成完全相同的一份 第二步：编写服务逻辑 在handler.go中填入函数 12345678// EchoImpl implements the last service interface defined in the IDL.type EchoImpl struct&#123;&#125;// Echo implements the EchoImpl interface.func (s *EchoImpl) Echo(ctx context.Context, req *api.Request) (resp *api.Response, err error) &#123; // TODO: Your code here... return &amp;api.Response&#123;Message: req.Message&#125;, nil&#125; 服务端需要其他变量时，应该可以在EchoImpl结构体中定义。 第三步：服务端编译运行12$ sh build.sh // 编译$ sh output/bootstrap.sh // 运行 第四步：编写客户端12345678910111213141516171819202122232425262728package mainimport ( &quot;context&quot; &quot;github.com/cloudwego/kitex/client&quot; &quot;kitex-learn/kitex_gen/api&quot; &quot;kitex-learn/kitex_gen/api/echo&quot; &quot;log&quot; &quot;time&quot;)func main() &#123; c, err := echo.NewClient(&quot;kitex-learn&quot;, client.WithHostPorts(&quot;0.0.0.0:8888&quot;)) if err != nil &#123; log.Fatal(err) &#125; req := &amp;api.Request&#123;&#125; for &#123; req.Message = time.Now().String() resp, err := c.Echo(context.Background(), req) if err != nil &#123; log.Fatal(err) &#125; log.Println(resp) time.Sleep(1 * time.Second) &#125;&#125; echo.NewClient的echo是包名，&quot;kitex-learn&quot;为使用kitex生成代码时传入的服务名。 c.Echo的Echo才是服务名，表示调用客户端实例c的Echo服务。 note的kitex代码 主目录的idl/note.thrift定义了note的服务接口。服务名为NoteService，包含5个服务：创建、删除、更新、查询、批量获取。 main.gomain.go的逻辑与示例代码略有不同，最大的区别是使用了etcd作为服务发现中心。在微服务应用中，运行的服务实例集会动态变更。实例有动态分配的网络位置。因此，为了让客户端向服务发出请求，它必须使用服务发现机制。服务发现的关键部分是服务注册中心。服务注册中心是一个可用服务实例的数据库。etcd是一个分布式K&#x2F;V数据库，本项目使用etcd作为服务发现中心。 main函数执行的任务： 在etcd服务发现中心注册note服务 用gorm初始化数据库连接 使用etcd服务发现解析user服务，创建了一个访问user服务的客户端，用于拉取用户列表 启动一个OpenTelemetry性能监视工具实例，用于监测note服务性能 启动note服务 handler.gohandler.go中每个功能的实现都大同小异，以查询功能QueryNote为例进行解析。 首先是验证req的数据的有效性： 1234if err = req.IsValid(); err != nil &#123; resp.BaseResp = pack.BuildBaseResp(errno.ParamErr) return resp, nil&#125; 这里用到的是thriftgo的一个插件：validator。当thrift文件定义了每个接口变量的数据范围时，validator插件会在kitex_gen文件夹中生成验证数据正确性的相应代码。 validator文档：Thrift Validator | CloudWeGo 在进行数据处理后，调用service文件夹中的对应函数进行具体处理： 1notes, total, err := service.NewQueryNoteService(ctx).QueryNoteService(req) 具体处理函数一方面用到了gorm接口操作数据库，另一方面用到了rpc文件夹中创建的客户端，连接到user服务，从user服务读取用户列表： 123noteModels, total, err := db.QueryNote(s.ctx, req.UserId, req.SearchKey, int(req.Limit), int(req.Offset)) // 使用gorm...userMap, err := rpc.MGetUser(s.ctx, &amp;demouser.MGetUserRequest&#123;UserIds: []int64&#123;req.UserId&#125;&#125;) // 使用rpc访问user服务 处理完成后，使用pack文件夹中定义的返回类型或Note类型构造返回值： 1234if err != nil &#123; resp.BaseResp = pack.BuildBaseResp(err) return resp, nil&#125; 总结一下每个文件夹的作用： service文件夹定义每个服务的具体处理逻辑 rpc文件夹定义访问user服务拉取用户列表的逻辑 pack文件夹定义服务的返回值 handler.go还涉及到一个内容：函数参数中的ctx context.Context变量。context.Context是Go标准库中定义的一个接口类型，从1.7版本中开始引入。其主要作用是在一次请求经过的所有协程或函数间传递取消信号及共享数据，以达到父协程对子协程的管理和控制的目的。需要注意的是context.Context的作用范围是一次请求的生命周期，即随着请求的产生而产生，随着本次请求的结束而结束。 api服务 hertz with thrift的代码构建流程第一步：创建thrift IDL IDL中指定请求的类型和URL URL语法先了解URL的通用语法： 1&lt;scheme&gt;://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt; scheme: 协议，常见的有 http（80），https（443），mailto，ftp（21），rtsp，rtspu，file。 user：用户名。 password： 密码。 host：主机。 port： 端口。 params: 参数。通常为 key=value。 query：查询参数或查询字符串。 frag: 片段（在浏览器中会被解析为 window.location.hash）。 IDL如下： 1234567891011121314namespace go hello.examplestruct HelloReq &#123;1: string Name (api.query=&quot;name&quot;);&#125;struct HelloResp &#123;1: string RespBody;&#125;service HelloService &#123;HelloResp HelloMethod(1: HelloReq request) (api.get=&quot;/hello&quot;);&#125; HelloMethod服务以路径为/hello的GET方法提供访问，请求中的Name变量被赋值为URL的query当中的name字段，例如：curl --location --request GET &#39;http://127.0.0.1:8888/hello?name=tom&#39;是一个GET请求，其中问号后面的部分为query，name字段的值为tom。 第二步：创建hertz项目12345// GOPATH 下执行hz new -idl idl/hello.thrift// 整理 &amp; 拉取依赖go mod tidy 生成的文件目录如下： 123456789101112131415161718192021222324.├── biz│ ├── handler│ │ ├── hello│ │ │ └── example│ │ │ └── hello_service.go│ │ └── ping.go│ ├── model│ │ └── hello│ │ └── example│ │ └── hello.go│ └── router│ ├── hello│ │ └── example│ │ ├── hello.go│ │ └── middleware.go│ └── register.go├── go.mod├── idl│ └── hello.thrift├── main.go├── router.go└── router_gen.go 第三步：修改handler handler文件夹中的hello_service.go为处理函数，文件夹名称hello/example是thrift IDL的namespace model文件夹定义了处理函数用到的数据结构和相关逻辑，无需且不能修改。 router文件夹定义了路由注册函数，其中只有middleware.go文件允许修改，可以定义中间件。 主目录的router.go中可以定义自定义路由规则。/ping路由就是在这个文件当中定义的。 主目录的router_gen.go为包装函数，依次调用router文件夹和router.go，分别注册由IDL定义的路由和自定义路由。","tags":[{"name":"Go","slug":"Go","permalink":"https://starman-swa.github.io/tags/Go/"},{"name":"后端","slug":"后端","permalink":"https://starman-swa.github.io/tags/%E5%90%8E%E7%AB%AF/"}],"categories":[{"name":"Go","slug":"Go","permalink":"https://starman-swa.github.io/categories/Go/"}]},{"title":"6.824 lab3b","date":"2023-01-25T09:00:04.000Z","path":"wiki/6-824-lab3b/","text":"设计思路实验3b需要解决的问题：如何判断snapshot的时机？persister.RaftStateSize()返回已经持久化的raft日志（连同若干个需要持久化的变量）的大小。server持续调用该函数，当返回值等于maxraftstate的时候进行snapshot。需要处理maxraftstate==-1的情况。snapshot时还需要传入snapshot对应的最后一条raft日志的下标，需要多维护一个变量。 snapshot包含什么？snapshot包含KV数据库的底层map和一些用于维护一致性的变量。当服务器重启时，Persister中保存的snapshot直接复制到server层即可。 maxraftstate是否需要持久化到Persister当中？不需要，因为maxraftstate是StartKVServer()的参数，在启动server时被传入。 当server从applyCh中读到snapshot时应该执行什么操作？直接覆盖原有database即可。 如何保证指令的去重？将maxOpIndexs保存到snapshot当中，进行持久化。 实验3b的一些注意事项： snapshot中保存的字段首字母大写 代码实现lab1-lab3完整实现代码：Starman-SWA&#x2F;6.824 (github.com)","tags":[{"name":"Raft","slug":"Raft","permalink":"https://starman-swa.github.io/tags/Raft/"},{"name":"Go","slug":"Go","permalink":"https://starman-swa.github.io/tags/Go/"},{"name":"KV数据库","slug":"KV数据库","permalink":"https://starman-swa.github.io/tags/KV%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"categories":[{"name":"分布式","slug":"分布式","permalink":"https://starman-swa.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"6.824 lab3a","date":"2023-01-15T10:28:26.000Z","path":"wiki/6-824-lab3a/","text":"简介相关资料MIT 6.824 Lab3 翻译（Key&#x2F;Value Server Base on Raft） - 知乎 (zhihu.com) 实现踩坑过程首先按照自己的思路进行了基本实现，踩了许多坑。 错误1： Test: one client (3A) 2022&#x2F;12&#x2F;06 17:12:56 2 server: Get RPC opf.opIndex&#x3D;&#x3D;3 but args.OpIndex&#x3D;&#x3D;5 原因：对于opIndex &#x3D;&#x3D; maxOpIndex的情况，这条指令也已经在raft层中Start一次commit了，也需要读取applyCh，而我忘记了。 错误2： Test: progress in majority (3A) 2022&#x2F;12&#x2F;06 18:22:20 2 server: Get RPC opf.opIndex&#x3D;&#x3D;1 but args.OpIndex&#x3D;&#x3D;2, opf&#x3D;&#x3D;{1 Put 1 14} 发现我忘了一件事情：就算不是leader，也要apply来自raft的日志（已实现，用一个goroutine来定期apply） 错误3： — FAIL: TestUnreliable3A (5.24s) test_test.go:293: get wrong value, key 3, wanted: x 3 0 yx 3 1 yx 3 2 yx 3 3 yx 3 4 yx 3 5 yx 3 6 yx 3 7 y , got x 3 0 yx 3 1 yx 3 2 yx 3 3 yx 3 4 yx 3 5 yx 3 6 yx 3 6 yx 3 7 y test_test.go:293: get wrong value, key 1, wanted: x 1 0 yx 1 1 yx 1 2 yx 1 3 yx 1 4 yx 1 5 yx 1 6 yx 1 7 yx 1 8 yx 1 9 yx 1 10 y , got x 1 0 yx 1 1 yx 1 2 yx 1 3 yx 1 4 yx 1 5 yx 1 6 yx 1 7 yx 1 8 yx 1 8 yx 1 9 yx 1 9 yx 1 10 y test_test.go:126: failure test_test.go:148: duplicate element x 1 8 y in Append result 当网络不稳定时，有一些指令被重复执行了。发现在server的RPC处理当中，我应该把判断OpIndex的逻辑写到Start前面，不然由于applyCh是单独的goroutine读取，在Start之后还是会重复执行提交但未回复的指令。 错误4： Test: completion after heal (3A) … — FAIL: TestOnePartition3A (6.21s) 1test_test.go:539: Put did not complete 发现没有实现超时机制。设计了一个map，保存每个client对应的已applied的opf，由RPC handler尝试读取，直至超时。实现超时后仍通不过，调试发现kv.maxOpIndexs应该写在applyLogs()协程里面。修改后通过该测试样例及之前的所有样例。 错误5： — FAIL: TestManyPartitionsOneClient3A (14.86s) test_test.go:293: get wrong value, key 0, wanted: x 0 0 yx 0 1 yx 0 2 yx 0 3 yx 0 4 yx 0 5 yx 0 6 yx 0 7 yx 0 8 yx 0 9 yx 0 10 yx 0 11 yx 0 12 yx 0 13 yx 0 14 yx 0 15 yx 0 16 yx 0 17 yx 0 18 yx 0 19 yx 0 20 yx 0 21 yx 0 22 yx 0 23 yx 0 24 yx 0 25 y , got x 0 0 yx 0 1 yx 0 2 yx 0 3 yx 0 4 yx 0 5 yx 0 6 yx 0 7 yx 0 8 yx 0 9 yx 0 10 yx 0 11 yx 0 12 yx 0 13 yx 0 14 yx 0 15 yx 0 16 yx 0 17 yx 0 18 yx 0 19 yx 0 20 yx 0 21 yx 0 22 yx 0 23 yx 0 24 yx 0 25 yx 0 25 y test_test.go:126: failure test_test.go:148: duplicate element x 0 25 y in Append result 在Partition测试中又出现重复写入。在applyLogs中去重后又发现：client让某个partition A apply了一个操作，当这个partition A和另一个partition B合并时，领导者变成了partition B的成员，但partition A的maxOpIndex更新，导致partition A无法执行新命令。 发现applyLogs的sleep应该删掉，否则apply太慢了。但是错误仍未解决。 继续跟踪Raft发现，旧leader向大多数节点append一个指令对应的日志成功后，在本地状态机进行了commit，并进行了apply，使得K&#x2F;V层的指令执行成功。但commit之后还来不及通过心跳或appendEntries让其他节点接收到leaderCommit，就变更领导者了，由于新领导者认为这个命令还未apply，所以无法执行后续指令。这应该就是实验指南和论文中提到的领导者变更问题。为了确保我的Raft实现没问题，用网上的lab3代码跑了一下3A，确定能够通过测试，从而将问题焦点落在server的实现上。 将代码进行了进一步检查和修改，又倒腾了一下午debug，终于通过所有算例。完整实现思路以下一章为准。 完整设计思路ClientClient向任意服务器发送请求，请求失败则换服务器重试，直到请求成功为止。每个Client以创建时的时间戳作为其ID，请求序号从1递增。 Serverserver数据结构： 123456789101112131415type KVServer struct &#123; mu sync.Mutex me int rf *raft.Raft applyCh chan raft.ApplyMsg dead int32 // set by Kill() maxraftstate int // snapshot if log grows this big // Your definitions here. table map[string]string // the database // appliedLogs string // for test maxOpIndexs map[int]int // the latest operation that server has applied for each client clientApplied map[int]chan OpFields&#125; table为存储K&#x2F;V对的哈希表，maxOpIndexs保存每个客户端已经applied的最大请求编号，clientApplied用于在server成功apply一个请求的时候通知Get&#x2F;PutAppend handler。 用于apply从Raft端提交的日志的go routine如下： 123456789101112131415161718192021222324func (kv *KVServer) applyLogs() &#123; for kv.killed() == false &#123; applyMsg := &lt;-kv.applyCh op, ok := applyMsg.Command.(Op) if !ok &#123; log.Fatal(errors.New(&quot;applyMsg type error&quot;)) &#125; opf := op.DecodeOp() DPrintf(&quot;%v server: applyCh receive logIdx: %v, OpIndex: %v, Key: %v, value: %v, ClientId: %v\\n&quot;, kv.me, applyMsg.CommandIndex, opf.opIndex, opf.key, opf.value, opf.ckId) kv.mu.Lock() if opf.opIndex &gt; kv.maxOpIndexs[opf.ckId] &#123; kv.OperatePutAppend(opf) kv.maxOpIndexs[opf.ckId] = opf.opIndex &#125; kv.mu.Unlock() select &#123; case kv.clientApplied[opf.ckId] &lt;- opf: default: &#125; &#125;&#125; 当Raft提交上来的日志编号大于当前应用的最大编号时，server才将其执行，以避免重复。然后，server借助kv.clientApplied中的channel告知Get&#x2F;PutAppend Handler请求已被提交。 这里的一个问题是为什么满足opf.opIndex &gt; kv.maxOpIndexs[opf.ckId]的请求就可以执行，而不需要opf.opIndex == kv.maxOpIndexs[opf.ckId]+1。这是我之前调试时一直犯的错误。我举个例子，假设当前对于某个客户端，MaxOpIndex为1，而opf.opIndex为3，那么此时有可能2还没有执行完，正在处于重试阶段，而用户就又输入了第三条指令。因此上述语句只需要保证不重复执行就行，而无需按照OpIndex顺序执行。 Get&#x2F;PutAppend Handler执行过程如下： 调用Start 通过Start的返回值判断是否为leader，若不为leader直接返回 判断是否args.OpIndex == kv.maxOpIndexs[args.ClientId]，若满足，则是论文中所提到的这条指令已经应用但未回复客户端的情况。此时直接回复即可。 在clientApplied中创建一个channel用于唤醒 使用select语句从channel中读取。若在规定时间内读取成功，需满足opf.opIndex &gt;= args.OpIndex才能回复成功；若读取超时，则回复Wrong Leader。 删除这个channel 关于加锁Client中的锁只作用与序列号，而没有作用于整个过程。这代表一个指令执行过程中，还可以交叉执行其他指令。指令最终在K&#x2F;V数据库中作用的顺序以指令开始被请求的顺序，即加锁确定序列号的前后顺序为准。 Server同理。","tags":[{"name":"Raft","slug":"Raft","permalink":"https://starman-swa.github.io/tags/Raft/"},{"name":"Go","slug":"Go","permalink":"https://starman-swa.github.io/tags/Go/"},{"name":"KV数据库","slug":"KV数据库","permalink":"https://starman-swa.github.io/tags/KV%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"categories":[{"name":"分布式","slug":"分布式","permalink":"https://starman-swa.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"Paxos算法笔记","date":"2023-01-12T08:02:47.000Z","path":"wiki/Paxos算法笔记/","text":"Basic PaxosBasic Paxos工作流程如下： 问题记录为什么Paxos使用两阶段协议？单阶段协议，无论是Accepter只接受第一个值或接受所有的值，都有可能会造成split vote或者多个值同时被chosen。 split vote的情况： 多个值被chosen的情况： 提案的值从何而来？case 1：Accepter返回PROMISE(n)之前已经accept过其他的提案，由于Paxos协议只允许对唯一一个value达成一致，因此即使这个PROMISE的序列号更高，其value也只能是之前accept过的value。 case 2：Accepter返回PROMISE(n)的时候还没有accpet过任何值，返回的PROMISE不带值，此时Proposal将客户端所请求的值放入ACCEPT请求当中。","tags":[{"name":"Paxos","slug":"Paxos","permalink":"https://starman-swa.github.io/tags/Paxos/"}],"categories":[{"name":"分布式","slug":"分布式","permalink":"https://starman-swa.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"6.824 lab2c, 2d","date":"2022-11-10T16:52:35.000Z","path":"wiki/6-824-lab2c-2d/","text":"Lab 2C实验2C要求实现Raft服务器currentTerm、votedFor和log三个状态的持久化，难度不高，只需要填充相应函数，并在每次回复RPC之前和这三个状态被修改之后调用持久化函数。 但实验2C的测试还是有可能因为2A、2B的实现不完善而发生错误。 我在测试时多次碰到该错误： — FAIL: TestFigure8Unreliable2C (41.85s)config.go:609: one(5768) failed to reach agreement 经过调试和查阅资料，发现了之前实验的两个错误实现： 在AppendEntries RPC当中直接将prevLogIndex之后的所有条目截断。当领导者向参与者发送的AppendEntries请求过期，其中包含的日志条目是参与者日志条目的子集的时候，这种实现会导致参与者的一部分正确日志被舍弃。正确的实现方法是严格按照论文，只截断冲突的日志。 原实现中，领导者收到AppendEntries的成功响应之后会执行nextIndex += len(args.Entries)。然而领导者在发送RPC之前已经释放了互斥锁，其nextIndex有可能被修改。正确实现应该是nextIndex = prevLogIndex + len(args.Entries) + 1。 此外，还进行了下列优化，顺利一次性通过了2A、2B、2C： TIME_STEP设为10ms，原实现与心跳超时相同。 选举超时设为[300, 450]ms，心跳超时设置为50ms。 Lab 2D实验2D要求实现快照功能。 实验官网的Hint给出了实现思路，按照思路，第一步是实现日志下标不从0开始存储。在我之前的实验中，日志下标以条目中的CommandIndex字段为准，故不需要做太多的修改。我原本的思路是在Raft状态中新增lastIncludedIndex和lastIncludedTerm两个字段，后来发现直接使用rf.log[0].CommandIndex和rf.log[0].CommandTerm来存储可以避免许多判断。 然而当我实现了第一步之后再去跑2C的测试时，发现总是会发生apply不一致或者不能reach agreement的错误，经过一番调试之后最终发现是AppendEntries()当中一个if的判断条件写错了，把args.Entries的长度写成了rf.log的长度。。。。。。。。。修改此bug后，顺利通过10次2C测试。 在跑2D的测试时发现另外的问题：当需要snapshot的时候，applyCh会阻塞，导致整个applyLogs线程阻塞。而由于applyLogs线程持有了互斥锁，因此整个服务器都会阻塞。解决方法是使用select语句： 12345678select &#123;case rf.applyCh &lt;- log: DPrintf(&quot;%v: applying log success, lastApplied==%v\\n&quot;, rf.me, rf.lastApplied)default: DPrintf(&quot;%v: applying log fail due to block, lastApplied==%v\\n&quot;, rf.me, rf.lastApplied) rf.lastApplied-- goto applyLogsLoopExit&#125; 当case中的写通道指令被阻塞时，select会转而执行default分支。需要注意不能在default分支中写break来退出外层循环，break的作用范围仅限于select，应该使用goto。 实现日志的部分存储之后就可以着手开始实现Snapshot函数和InstallSnapshot RPC。实现前，要先理解Snapshot的指令和数据流向：上层应用在不需要前一部分的日志时，会调用Raft的Snapshot方法，其snapshot参数是上层应用已经创建好的快照。Snapshot方法需要做的是：截断日志，然后将快照snapshot持久化到持久性存储当中。当领导者发现某个参与者的nextIndex小于等于当前的lastIncludedIndex时，需要发送InstallSnapshot RPC，此时通过Persister.ReadSnapshot方法可从持久化存储中读取快照进行发送。 由config.go第247行还可以知道：snapshot字节数组使用labgob包编解码，首先包含lastIncludedIndex数值，然后顺序包含lastIncludedIndex及之前的所有日志条目。 Snapshot的函数调用关系比较难理解，需要参考Raft Diagram。 Service为使用Raft Code作为其一致性协议的上层应用，可以是K&#x2F;V数据库等。 为了避免在Raft Code的内存中保留过长的日志条目，Service会定期将已经apply的一部分日志转换为snapshot。Snapshot的创建仅由Service执行。当Snapshot被创建之后，Service会调用Snapshot()方法通知Raft Code对其内存中的日志条目进行截断，方法的参数为已经创建的snapshot字节切片，以及lastIncludedIndex。 Raft Code接收到Service的Snapshot()请求之后，对其日志中下标为lastIncludedIndex及之前的条目截断，并将snapshot保存到内存当中，用于可能的InstallSnapshot RPC。当Raft Code接收到snapshot后，需要立即将其持久化。 Raft Code崩溃重启时，Service会调用ReadSnapshot()方法读取已经保存的snapshot，并进行apply，Raft Code无需再apply这部分状态。然而，为了用于可能的InstallSnapshot RPC，Raft Code也需要立即调用ReadSnapshot()方法将snapshot保存到内存中，注意这个调用关系在Raft Diagram当中没有体现。 如果领导者的nextIndex[i]小于等于lastIncludedIndex，说明此时节点i由于某种原因严重落后，需要领导者的snapshot中的日志条目。领导者发送InstallSnapshot RPC给节点i。 节点i收到InstallSnapshot RPC请求后，将snapshot通过applyCh应用到Service的状态机上。然后，Service会调用CondInstallSnapshot()告知Raft Code其已经将刚刚传入的snapshot应用，该方法为旧版6.824实验中的冗余要求，直接返回true即可。 在熟悉以上架构的基础上就可以很容易地写出代码。同样的，创建一个后台goroutine，重复检查领导者的nextIndex数组，当发现nextIndex[i]&lt;=lastIncludedIndex的时候开始发送InstallSnapshot RPC。 可能会出错的地方有： 每次调用rf.persister.SaveStateAndSnapshot()方法的时候都必须传入当前内存中的snapshot，不能在不需要更新snapshot的时候传入nil，否则会覆盖持久化存储当中的snapshot。 当使用labgob包对snapshot进行解码之后，由于snapshot当中可能包含当前解码位置的指针，snapshot的二进制内容会发生变化。InstallSnapshot RPC接收者实现的第5个步骤需要用到snapshot的lastIncludedIndex，此时不能通过解码snapshot的方式读取该值，而必须使用args.LastIncludedIndex，否则会出错。 在InstallSnapshot RPC中，persist的时机很重要。必须保证在snapshot和rf.log[0]（即lastIncluded信息）同时更改之后才能persist，不能只更新了某个值就persist。 在领导者发送snapshot的不同chunk的过程中，必须保证参数中的Term、LastIncludeIndex和LastIncludedTerm保持不变，即使领导者的状态已经发生了改变。即要把这几个变量提出循环外。在发送snapshot的多个chunk的过程中，领导者的snapshot可能会发生追加，我目前采用的策略是继续发送原有的snapshot。猜测更好的策略应当是丢弃原有的snapshot，重新发送新的snapshot，以节省网络带宽。这一点留待后续优化。 感想6.824的lab2到这里就告一段落了，总算是完整地实现了Raft算法，还蛮有成就感的。在完成这四个小实验的过程中，我也能明显地感觉到自己在代码调试能力和写作能力这两个方面的提升。代码调试上，面对密密麻麻，动辄几个GB的调试信息，我不再有畏难心理了。我学会了在代码恰当的地方输出结构化的调试信息，在调试信息中寻找关键点，进行调试。可以说，我离”松弛感“又更进一步了。在写作能力上，从lab2a到lab2d，我也在逐渐摆脱”报告文学“。总而言之，6.824陪伴我度过了一段快乐的时光。","tags":[{"name":"Raft","slug":"Raft","permalink":"https://starman-swa.github.io/tags/Raft/"},{"name":"Go","slug":"Go","permalink":"https://starman-swa.github.io/tags/Go/"}],"categories":[{"name":"分布式","slug":"分布式","permalink":"https://starman-swa.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"6.824 lab2a, 2b","date":"2022-10-19T11:54:47.000Z","path":"wiki/6-824-lab2a-2b/","text":"简介6.824 lab2a、2b要求实现raft算法的领导选举和日志追加部分。 相关资料 Lab2翻译：MIT 6.824 Lab2 翻译 （已完成）（Raft Base on Golang） - 知乎 (zhihu.com) Raft论文翻译：Raft一致性算法中文翻译版(格式同原论文) - 简书 (jianshu.com) 实验指南翻译： MIT 6.824 - Lab 2 (1): Students’ Guide to Raft - 知乎 (zhihu.com) MIT 6.824 - Lab 2 (2): Raft Locking Advice - 知乎 (zhihu.com) learningNotes&#x2F;[翻译]Lab2: Raft Structure Advice.md at main · raygift&#x2F;learningNotes (github.com) sync.Cond包介绍：Go sync.Cond | Go 语言高性能编程 | 极客兔兔 (geektutu.com) Raft算法Raft算法的核心可参考Raft原论文In Search of an Understandable Consensus Algorithm的Figure 2，以下为中文翻译。 State所有服务器上需要被持久化的状态（回复RPC之前在稳定存储介质中更新） currentTerm：服务器看见的最新任期（第一次启动时初始化为0，单调增加） votedFor：在当前任期收到的投票请求的候选者ID（若没有，则为null） **log[]**：日志记录；每条记录包含用于状态机的指令，以及领导者收到此条记录时的任期（第一个下标为1） 所有服务器上可变的状态： commitIndex：已知的被提交的最大下标（初始化为0，单调增加） lastApplied：被应用到状态机的最大下标（初始化为0，单调增加） 领导者的可变状态（选举后重新初始化） **nextIndex[]**：对于每个服务器，为即将发送给这个服务器的记录的下标（初始化为领导者最后一条记录的下标+1） **matchIndex[]**：对于每个服务器，为已知的被复制到该服务器的最大下标（初始化为0，单调增加） AppendEntries RPC参数： term：领导者任期 leaderId：使得参与者可以重定向客户端 prevLogIndex：新记录的直接前驱记录的下标 prevLogTerm：新纪录的直接前驱记录的任期 **entries[]**：新纪录（心跳则为空，为了效率可以发送多个记录） leaderCommit：领导者的commitIndex 结果： term：currentTerm，供领导者更新自己 success：如果参与者包含与prevLogIndex和prevLogTerm相匹配的记录，则为真 接收者实现： 如果term&lt;currentTerm，返回假 如果不包含与prevLogIndex和prevLogTerm相匹配的记录，则返回假 如果一条现有的记录与新纪录冲突（下标相同但任期不同），删除这条现有的条目，以及所有后继的条目 将不在log当中的所有记录追加到log当中 如果leaderCommit&gt;commitIndex，设置commitIndex&#x3D;min(leaderCommit, 最后一条新记录的下标) RequestVote RPC参数： term：候选者任期 candidateId：候选者ID lastLogIndex：候选者最后一条记录的下标 lastLogTerm：候选者最后一条记录的任期 结果： term：currentTerm，供候选者更新自己 voteGranted：为真意味着候选者收到一票 接收者实现： 如果term&lt;currentTerm，返回假 如果votedFor为null或者candidateId，并且候选者的记录至少与接收者一样新（下面会定义），则投票 所有服务器的规则所有服务器： 如果commitIndex&gt;lastApplied：递增lastApplied，将log[lastApplied]应用到状态机 如果RPC请求或RPC回复中包含的任期T&gt;currentTerm：设置currentTerm&#x3D;T，转换为参与者 参与者： 回复来自候选者和领导者的RPC 如果在选举超时时间内，没有收到来自当前领导者的AppendEntries RPC或没有投票给候选者：转变为领导者 候选者： 当转变为候选者时，开始选举： 递增currentTerm 投票给自己 重置选举定时器 发送RequestVote RPC给所有其他服务器 如果收到来自大多数服务器的投票：转变为领导者 如果收到来自新领导者的AppendEntries RPC：转变为参与者 如果选举超时：开始新的选举 领导者： 当选举之后：发送初始的空AppendEntries RPC（心跳）给每个服务器；在空闲时段内重复发送，以避免选举超时 如果收到来自客户端的命令：追加命令到本地的log，在将命令应用到状态机之后回复客户端 如果最后一条记录的下标&gt;&#x3D;某个参与者的nextIndex：发送由AppendEntries RPC，包含由nextIndex开始的记录 如果成功：更新每个参与者的nextIndex和matchIndex 如果由于记录的不一致而失败：递减nextIndex并重试 如果存在一个N，使得N&gt;commitIndex，大多数的matchIndex[i]&gt;&#x3D;N，且log[N].term &#x3D;&#x3D; currentTerm：设置commitIndex&#x3D;N 实现注意事项 RequestVote RPC中比较日志新旧的方法在5.4.1中提到：如果两个日志最后的记录的任期不同，则包含更新任期记录的日志更新；如果两份日志最后的记录的任期相同，则更长的日志更新 日志记录的下标从1开始，为了方便访问和避免下标越界，每个服务器在启动时都会先包含一个空记录 实验提供的代码模板当中，日志记录包含下标字段。但下标可用切片的下标直接代替，目前实验暂不需要用到下标字段。考虑到后续实验有可能会用到，仍使用该字段而不是切片下标作为日志记录的下标 实验提供的代码模板当中的日志记录不包含任期字段，暂不清楚原因，实现中手动添加了该字段 实验提供的代码模板中未包含领导者应用状态机之后回复客户端的方式，未实现 所有服务器的规则2在每次处理RPC请求和收到RPC回复的时候均需要实现，容易遗漏 AppendEntries RPC的接收者实现步骤3、4可以合并为：删除prevLogIndex之后的所有记录，然后追加所有新记录。在后续持久化的实验当中可能需要再进行更改。步骤3的原意是prevLogIndex之后的记录与新记录可能存在部分匹配，暂未想到出现这种情况的场景。 实现方式goroutine的使用除了RPC和外部接口之外，系统的所有功能都通过goroutine实现。按照功能划分，这些goroutine可分为两种类型：监听型和触发型。 监听型goroutineRaft算法包含一些需要在后台不断监听，在符合条件时执行的操作，包括： 候选者和参与者的选举超时 领导者的心跳发送 领导者的AppendEntries RPC发送 每个服务器日志记录的应用 领导者commitIndex变量的更新 这些操作各自通过一个goroutine实现，在Make函数中创建，goroutine循环检查rf.killed()的值，为真时goroutine退出，否则，在一段时间间隔之后执行相应操作，在执行操作之前可能还需要检查动作触发条件是否满足，如服务器是否为某个状态。 触发型goroutineRaft算法中包含一些由动作触发的过程，包括： 候选者规则1、2、3 一般的函数调用是顺序执行的，调用者在函数返回前会阻塞。如果调用者是一个监听型goroutine，会导致系统暂时无法监听该功能。因此上述过程也需要通过goroutine实现，调用者与该goroutine进行通信，触发该功能运行，然后立即返回。 这种一个调用者触发一个或多个特定的被调用者执行的并行模型可以使用Go的sync.Cond包实现。数据结构定义如下： 123cond *sync.CondcondLock sync.MutexwakeUpType int 包含一个sync.Cond类，一个锁和一个条件变量。教程中提到这个锁可以是互斥锁或读写锁，但我查阅了sync.Cond的实现，发现sync.Cond类中关联的锁只实现了Lock()和Unlock()这两个方法，对应读写锁中的写锁操作，而无法执行读锁操作。因此我暂时还没搞明白如何搭配sync.Cond和读写锁。上述并行模型采用互斥锁即可实现，这个锁传入NewCond()方法与Cond类进行关联，可以单独定义，也可以使用cond.L字段。 初始化： 12rf.cond = sync.NewCond(&amp;rf.condLock)rf.wakeUpType = NONE 调用者实现： 123456if rf.state != LEADER &#123; rf.condLock.Lock() rf.wakeUpType = NEW_ELECTION rf.condLock.Unlock() rf.cond.Broadcast()&#125; 调用者通过cond.Broadcast()方法唤醒所有被cond阻塞的goroutine，唤醒时无需锁的保护。 被调用者实现： 12345678910for rf.killed() == false &#123; rf.condLock.Lock() for rf.wakeUpType != NEW_ELECTION &#123; rf.cond.Wait() &#125; rf.wakeUpType = NONE rf.condLock.Unlock() [功能实现]&#125; 其中，cond.Wait()方法会释放锁，阻塞当前goroutine，直到被唤醒，被唤醒时会加锁，然后再次检查for循环的条件是否满足，如果满足，才跳出循环，释放锁，执行功能。此处的for循环是必要的，不能用if代替，因为Broadcast()方法会唤醒所有被cond阻塞的goroutine，但只有符合对应功能的goroutine需要被执行，其他goroutine需要再次阻塞。 锁的使用服务器的状态用一把互斥锁rf.mu保护。 锁的使用注意事项： 对服务器状态的任何读写操作均需要锁保护 一个完整的过程需要全程用锁保护，以保证状态的一致性和过程的原子性。 RPC调用应当是一个非阻塞的过程，调用前应当解锁。调用后的服务器状态可能会发生变化（例如候选者发送选举请求后发现有其他任期更高的领导者而转变成参与者），应当在加锁之后检查服务器状态是否发生改变。 错误与调试这个错误花了我比较长的时间debug，还伴随着其他错误： — FAIL: TestFailAgree2B (13.48s) config.go:609: one(106) failed to reach agreement 阅读调试信息后发现，“106”指令被重复多次地追加到参与者的日志当中，且一直没有被apply。判断为matchIndex的值错误导致commitIndex没有及时更新的问题。从而发现在AppendEntries RPC返回之后，nextIndex被错误地写成了加1，而不是加上AppendEntries RPC参数中log的长度，导致matchIndex的值错误。","tags":[{"name":"Raft","slug":"Raft","permalink":"https://starman-swa.github.io/tags/Raft/"},{"name":"Go","slug":"Go","permalink":"https://starman-swa.github.io/tags/Go/"}],"categories":[{"name":"分布式","slug":"分布式","permalink":"https://starman-swa.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"6.824 lab1","date":"2022-10-05T08:33:25.000Z","path":"wiki/6-824-lab1/","text":"6.824简介6.824为MIT的分布式系统课程。同TinyKV类似，6.824的主要内容也为实现Raft共识算法。以笔者做完Lab1的感受，相比TinyKV，6.824仅提供了基本框架，在测试用例当中并未对实现过程中所使用的数据结构进行具体要求，因此编程自由度较高。 相关资料6.824 Home Page: Spring 2022 MIT6.824分布式系统课程中文翻译 - 知乎 (zhihu.com) 如何的才能更好地学习 MIT6.824 分布式系统课程？ - 知乎 (zhihu.com) 【MIT 6.824 Distributed Systems Spring 2020 分布式系统 中文翻译版合集】_哔哩哔哩_bilibili 实验要求实现一个分布式的MapReduce系统，实验文档中文翻译参照： 【翻译】6.824 lab1 （自用不负责） - Greenty - 博客园 (cnblogs.com) MapReduceMapReduce是Google提出的一个软件架构，用于大规模数据集的并行运算。MapReduce包含Map和Reduce两个步骤，可以用函数来表示。 Map函数读取一个文件，根据文件内容输出一个称为中间件的键值对列表。每个Map函数分别处理一个输入文件。 1func Map(fileName string, content string) intermediates []KVPair 所有Map函数输出的中间件集合在一起，作为完整的中间件。对于中间件中每个不同的key对应的所有键值对，分别执行一个Reduce函数。Reduce函数根据键值对列表的内容输出这个key对应的一个value。 1func Reduce(key string, values []string) string 整个MapReduce流程的输入为文件列表，输出为键值对列表。 系统实现MapReduce的分布式执行系统包含一个master（coordinator）和若干个worker。master负责任务分发、协调任务的运行，worker负责执行具体的map和reduce函数。master启动后，执行注册RPC的操作，使得其方法对worker可见。worker通过本地网络对master的方法进行远程调用。 注意：使用RPC包时，外部方法名称和被传输结构体当中的成员名称的首字母均需要大写，否则会出现数据无法正常传输的错误。 worker由于master无法知道worker的存在，也无法知道worker是否故障，因此worker的主循环中需要反复向master请求分发任务，在任务完成之后需要向master发送完成信息，分别对应master的DispatchTask和HandleTaskDone两个方法。worker主循环如下，master返回TASK_WAIT时代表map任务未全部完成，worker等待一段时间之后再次向master请求可能的reduce任务或者超时的map任务。 123456789101112for &#123; reply := SendRequest() if reply == nil || reply.TaskType == TASK_NONE &#123; break &#125; else if reply.TaskType == TASK_MAP &#123; doMap(reply, mapf) &#125; else if reply.TaskType == TASK_REDUCE &#123; doReduce(reply, reducef) &#125; else &#123; // TASK_WAIT time.Sleep(100 * time.Millisecond) &#125;&#125; mastermaster结构体定义如下： 12345678910111213141516type Coordinator struct &#123; // Your definitions here. files []string nReduce int nodeId int // dispatch task with a node id to identify temp files generated by different nodes mapStates []int // 0:not dispatched, 1:dispatched, 2:done, 3:dispatched_timeout mapIds []int mapDone bool mapMutex sync.Mutex reduceStates []int // 0:not dispatched, 1:dispatched, 2:done, 3:dispatched_timeout reduceIds []int reduceDone bool reduceMutex sync.Mutex&#125; master将每个map任务和每个reduce任务的状态分别保存与mapStates和reduceStates切片中，0表示未分发，1表示已分发但未完成，2表示完成，3表示超时（在下一节会详细介绍超时处理）。在DispatchTask方法中，master首先根据mapDone变量判断map是否完成，然后相应地遍历mapStates或reduceStates切片，找到第一个未分发的任务进行分发。由于两个切片和两个done变量可能同时被多个worker访问，需进行加锁。我用了mapMutex和reduceMutex两把锁。 超时处理超时检测当master持续一段时间未收到来自worker的完成信息时，可认为对应的worker故障或者速度太慢，此时需要重新分发任务。可以通过新建一个goroutine进行后台计时。goroutine会在父函数返回的时候退出，因此不能在DispatchTask方法当中对于每个任务单独创建一个用于计时的goroutine，否则，当RPC调用返回的时候，这个goroutine也会随之结束。 由上，goroutine只能在MakeCoordinator函数中创建。出于简洁性，我实现了如下函数： 1234567891011121314151617181920212223242526272829go func() &#123; for &#123; if c.Done() &#123; break &#125; //fmt.Printf(&quot;checking timeout\\n&quot;) time.Sleep(10 * time.Second) c.mapMutex.Lock() for i, state := range c.mapStates &#123; if state == 1 &#123; c.mapStates[i] = 3 &#125; else if state == 3 &#123; fmt.Printf(&quot;map timeout %v\\n&quot;, i) c.mapStates[i] = 0 &#125; &#125; c.mapMutex.Unlock() c.reduceMutex.Lock() for i, state := range c.reduceStates &#123; if state == 1 &#123; c.reduceStates[i] = 3 &#125; else if state == 3 &#123; fmt.Printf(&quot;reduce timeout %v\\n&quot;, i) c.reduceStates[i] = 0 &#125; &#125; c.reduceMutex.Unlock() &#125;&#125;() 该goroutine每隔一段时间检查state的值，当state为1时，将其设为3。当state为3时视为超时。该实现的超时时间不是固定的，而是一个范围，但在实现上较为简洁。 临时文件处理假设超时是由于节点速度过慢，当新节点被指派重复执行该任务的时候，新节点和旧节点产生的临时文件会冲突。因此，我在worker生成的临时文件的文件名当中加上了节点的ID以进行区分，当worker向master报告任务完成之后，master才将对应节点产生的临时文件重命名为所需要的形式。为了避免因某个任务的基础执行时间超过了超时阈值而导致的重复超时，master在接收到任意一个worker报告的完成信息时立即将该任务标记为完成，即使该worker已经超时。","tags":[{"name":"Go","slug":"Go","permalink":"https://starman-swa.github.io/tags/Go/"},{"name":"MapReduce","slug":"MapReduce","permalink":"https://starman-swa.github.io/tags/MapReduce/"}],"categories":[{"name":"分布式","slug":"分布式","permalink":"https://starman-swa.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"In Search of an Understandable Consensus Algorithm - Raft","date":"2021-12-13T07:43:06.000Z","path":"wiki/In-Search-of-an-Understandable-Consensus-Algorithm-Raft/","text":"摘要Raft是一个用于管理replicated log的共识算法（consensus algorithm）。Raft与Paxos一样高效。相比Paxos，Raft更加易懂，且为应用到实际系统当中提供了更好的基础。为了提高可理解性，Raft将共识算法的几个关键元素分开，例如leader election、log replication和safety，并且它通过执行更强的一致性减少了需要考虑的状态数目。 引入共识算法能够让一群机器作为一个团结一致的群体运行，且能够容忍其中部分成员的失效。因此，共识算法在建立可靠的大规模软件系统当中发挥了重要作用。目前，几乎所有的共识算法都是基于Paxos，或受其影响的。但Paxos有两个缺点： 难以理解。 不能为构建实际系统提供一个很好的基础。为了应用到实际系统，需要进行复杂的更改。 Raft的提出就是为了改善这两个问题。Raft有以下几个新的特征： Strong leader：相比其他共识算法，Raft使用了一种更强的领导形式。例如，log entries只从leader传输到其他服务器。这简化了replicated log的管理，并且使得Raft更易懂。 Leader election：Raft使用了随机的计时器来选举领导。这是在其他共识算法已有的心跳机制的基础上进行的小规模的修改，但却简单迅速地解决了冲突。 Membership changes：Raft再更改集群中服务器集合的时候采用了新的joint consensus方法，两种不同配置的大多数服务器在转换过程中会重叠。这使得集群在配置更改的过程中仍然能正常运行。 Replicated state machines共识算法被应用的典型场景是Replicated state machines，其中，一群机器上的状态机计算相同状态的副本，并且在部分服务器失效的情况下也能继续运行。Replicated state machines被用于解决分布式系统中的容错问题。 如下图，Replicated state machines通常使用replicated log实现。每个服务器存储一个包含一系列指令的日志，状态机顺序执行这些指令。所有状态机按同样的顺序存储相同的指令，得到相同的输出序列。 实际系统中的共识算法通常具有下列性质： 在非拜占庭条件之下保证安全（不返回错误的结果）。非拜占庭条件指的是可以出现故障，但信息不能被伪造，例如网络延迟、丢包、重复、失序。与之相对应的是信息被伪造的拜占庭错误。 当大多数服务器可用且能够互相发送信息时，集群就是可用的。例如，拥有5个服务器的典型集群能够容忍2个服务器的失效。 不依赖于计时器来保证日志的一致性，错误的时钟和极端的消息延迟在最坏情况下也只会造成可用性问题，而不会影响一致性。 通常情况下，一旦集群中的大多数服务器对一轮RPC完成一次响应，集群就完成了一条指令的执行；少数慢速服务器不会影响系统的整体性能。 Raft算法Raft将共识问题分解为下列几个相对独立的子问题： Leader election：当现有的leader失效时，一个新的leader被选出。 Log replication：leader从客户端接收log entries，在集群中复制，保证其他日志与之一致。 Safety：Raft在任何时候保证下列每一条性质。 Election Safety：在一个给定的term当中，至多一个leader被选出。 Leader Append-Only：一个leader从不覆写或删除其日志中的entries；leader只附加新的entries。 Log Matching：如果两份日志包含一条拥有相同index和term的entry，那么这两份日志中所有给定index的entry都是相同的。 Leader Completeness：如果一个log entry在一个给定的term当中提交，那么这个entry将会在所有term更高的leaders的日志当中出现。 State Machine Safety：如果一个服务器将一个给定index的log entry应用到它的状态机上，那么其他服务器将永远不会在相同的index上应用一个不同的log entry。 Raft基本定义服务器的三种状态一个Raft集群由若干个服务器组成。在任意给定的时刻，每个服务器处于下列三种状态中的一种：leader、follower、candidate。在正常运行时，仅有一个leader，其他服务器均为follower。follower都是被动的：它们不会自己发送请求，只会响应来自leader和candidate的请求。leader处理所有的客户端请求（若客户端联系follower，follower将请求重定向到leader）。candidate用于选举新的leader。 上述三个状态的状态转移图如下： 时间划分：termRaft将时间划分为任意长度的terms，用连续的整数表示。每个term起始于选举，此时有一个或多个candidate尝试成为leader。如果某一个candidate赢得了选举，在这个term的剩余时间当中它将作为集群唯一的leader。如果选举不出leader，例如两个candidate同票，那么这个term直接结束，进入下一个term，开始一场新的选举。 term在Raft中充当逻辑时钟的角色，使得服务器能够检测过时的信息，例如过时的leader。每个服务器存储一个current term数值，在每次通信时发送自己的current term。当某个服务器接收到一个包含比自己大的current term的请求时，它会更新current term为这个更大的值。如果这个服务器是candidate或者leader，他会返回follower状态。反之，当服务器接收到一个包含过时的、比自己小的term的请求时，它会拒绝这个请求。 RPC类型Raft服务器之间使用RPC进行通信。基本的共识算法只需要两种类型的RPC： RequestVote RPC，由candidate初始化，用于请求其他服务器投票。 AppendEntries RPC，由leader初始化，用于复制log entry和提供心跳信号。 Raft还加入了第三种类型的RPC，用于在服务器之间传输snapshot。 如果服务器没有及时收到响应，它们会重试RPC。服务器以并行的方式处理RPC。 Leader electionRaft使用心跳机制来触发leader election。服务器启动时为follower状态，且只要它收到来自leader或candidate的有效的RPC，它就会维持follower状态。leader会定期发送心跳信号（即空的AppendEntries RPC）给所有follower来维持它的权威。如果一个follower在一段叫做election timeout的时间之后还没有收到通信，则它认为没有可见的leader，从而开始一次新的选举。 为了开始一次选举，一个follower将它的current term加一，然后进入candidate状态。它会投票给自己，然后并行地在集群中的其他服务器上执行RequestVote RPC。 candidate维持其状态，直到下列三者之一发生： 它赢得了选举。当candidate收到整个集群（full cluster）中大多数服务器的相同term的投票时，它将赢得选举成为leader。在给定的term当中，服务器根据FCFS策略投票给第一个candidate。 另一个服务器赢得选举，成为leader。在等待投票的过程中，如果candidate收到AppendEntries RPC，且发送者的term号大于等于服务器自身的term，则说明另一个服务器已经成为leader。本服务器转为follower。 一段时间后，没有服务器赢得选举。此时每个服务器都会超时，并且开始一场新的选举。为避免这种情况无穷无尽地出现，Raft使用随机的election timeout，即从一个给定的间隔中随机选取（如150-300ms）。这使得在大多数情况下只有一个服务器超时，并且它在其他服务器超时之前就已经成为leader并发送了心跳信号。 Log replicationleader处理客户端请求。每条客户端请求包含一条将被replicated state machines执行的指令。leader将这条指令以一个新的entry的形式添加到日志末尾，然后对其他服务器并行地执行AppendEntries RPC，以复制这条entry。当entry被安全复制之后，leader对其自己的状态机应用这条entry，然后返回执行结果给客户端。如果由于follower服务器失效、运行速度过慢或网络丢包等原因导致log entry无法被复制到该follower上面，leader会无穷无尽地重试AppendEntries RPC，即使它已经回复了客户端的请求也是如此，直到所有的follower都存储了所有的log entry。 Log的形式如下图所示。 当一条log entry能够被安全地应用到leader的状态机上时，我们称之为一条被提交的entry。Raft保证被提交的entry是持久的，且最终会被应用于所有有效的状态机上。当创建这条entry的leader将其复制到大多数服务器上之后，这条entry就被提交。同时，leader的日志中所有之前的entry也会被一并提交，包括先前其他leader创建的entry。 leader持续追踪已被提交的最大index，并且在AppendEntries RPC中包含这个index。一旦一个follower得知某条log entry被提交，它就会将这条entry应用到自己的local状态机上。 Raft维持下列两条性质，共同构成了上述提到的Log Matching Property： 如果不同log当中的两条entry拥有相同的index和term，那么他们存储相同的指令。 如果不同log当中的两条entry拥有相同的index和term，那么这两个log之前的entry完全一样。 第一条性质的正确性来源于：leader至多创建一条给定index和term的entry，且entry不会在log中更改位置。第二条性质的正确性来源于AppendEntries的简单一致性检查。当发送AppendEntries RPC时，leader会包含上一个entry的index和term。如果follower没有在其日志中找到相同的index和term，它会拒绝新的entry的添加。 在正常运行的情况下，leader和follower的日志是一致的。但是leader的失效会导致不一致，因为旧的leader可能没有完成其日志中所有entry的复制。下图为几种可能的情况： 服务器的日志有可能缺失当前leader中的entry，也有可能拥有leader中没有的entry，或两者皆发生。且有可能横跨多个term。 在Raft当中，leader通过强制follower复制其日志的方式来处理不一致。这意味着follower中冲突的日志将会被leader对应的entry覆盖。为了达到一致性，leader必须找到两份日志当中最后一个相同的entry，删除follower日志中在此之后的entry，然后向follower其发送leader日志中在此之后的所有entry。leader对每一个follower维护一个nextIndex变量，表示leader将发送给follower的下一个entry的index。当服务器成为leader的时候，它会将所有nextIndex值初始化为其log的下一个号码。如果entry不一致，AppendEntries一致性检查会在下一个AppendEntries RPC中失败。在收到拒绝之后，leader将nextIndex减1，然后重试AppendEntries RPC，直至成功，然后再向后添加正确的entry。 一些问题Q: Log的作用是什么？Log中存储的历史指令在什么时候需要用到？ Q: Log中存储term号的作用？ Q: 假如一个leader服务器的部分entry还没有被提交时，这个服务器就故障了，但故障时间很短，它马上又成为了leader。根据Leader Append-Only Rule，这个leader存储的未提交的错误entry不能被删除。请问这种情况有可能发生吗？ Q: 当一个leader故障时，如何保证新选出来的leader的log是正确的？ Q: entry什么时候被应用于follower的状态机上？还是说没有必要应用？","tags":[{"name":"Raft","slug":"Raft","permalink":"https://starman-swa.github.io/tags/Raft/"}],"categories":[{"name":"分布式","slug":"分布式","permalink":"https://starman-swa.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"TinyKV Project 1 - Standalone KV","date":"2021-11-18T07:36:49.000Z","path":"wiki/TinyKV Project 1 - Standalone KV/","text":"任务目的熟悉Go语法，熟悉面向对象程序设计。 任务说明Project1需要实现一个单节点、非分布式的K&#x2F;V存储gRPC服务，本质上是对BadgerDB进行封装，以实现Put&#x2F;Delete&#x2F;Get&#x2F;Scan四种基本操作，以及对Column Family的支持。 该Project大致分为两部分： StandAloneStorage类的实现。StandAloneStorage类实现了Storage接口，Storage接口提供了用于操作K&#x2F;V数据库的Start、Stop、Write、Reader四个方法，对于StandAlone的数据库来说，这四个方法就是对底层的BadgerDB进行读写。 Raw API的实现。Raw API为服务器对外暴露的API，用于接收请求，通过调用StandAloneStorage类的方法处理请求，然后返回响应。Raw API需要实现前述的四种基本操作。 上述调用关系如下图所示： 任务实现StandAloneStorage类的实现StandAloneStorage类的实现基本不需要直接使用BadgerDB的方法，因为engine_util包中已经封装了许多操作BadgerDB的方法，且支持了Column Family，直接调用即可。 func NewStandAloneStorage该函数不是StandAloneStorage类的方法，接收config，返回一个新创建的StandAloneStorage指针。由于engines.go文件中封装的方法都以Engines类作为接收者，我们需要在创建StandAloneStorage的时候创建一个Engines实例。 1234567891011type StandAloneStorage struct &#123; // Your Data Here (1). en *engine_util.Engines&#125;func NewStandAloneStorage(conf *config.Config) *StandAloneStorage &#123; // Your Code Here (1). kvdb := engine_util.CreateDB(conf.DBPath, false) raftdb := engine_util.CreateDB(conf.DBPath+&quot;/raft&quot;, true) return &amp;StandAloneStorage&#123;engine_util.NewEngines(kvdb, raftdb, conf.DBPath, conf.DBPath+&quot;/raft&quot;)&#125;&#125; Raft Engine在Project1中暂时不需要用到，但如果设为nil，自带的Engines.Close方法会尝试调用nil.Close()，引发错误，因此必须进行创建。 func Start根据Badger官方文档，一个Badger数据库通过Open方法打开后即可使用，最后再通过Close方法关闭。NewStandAloneStorage函数中调用的CreateDB函数已经调用了Open方法，此时数据库已经可以使用，因此Start方法无需执行任何操作。 1234func (s *StandAloneStorage) Start() error &#123; // Your Code Here (1). return nil&#125; func StopEngines.Destroy一方面调用Engines.Close，关闭两个BadgerDB，另一方面删除目录。 1234func (s *StandAloneStorage) Stop() error &#123; // Your Code Here (1). return s.en.Destroy()&#125; func WriteWrite方法接收一个名为batch，元素类型为storage.Modify的切片。Modify类包含一个接口成员Data，Data可以为Put类型或者Delete类型，分别对应增加和删除操作。Put类型包含Key、Value和Cf三个成员，而Delete类型没有Value成员。 engine_util包中的WriteBatch类提供了写入KV对到数据库的方法WriteToDB。对于Write方法的实现，我们遍历Modify切片，对于每个修改项利用WriteBatch.SetCF方法将其附加到WriteBatch的底层切片末尾（类型为badger.Entry），最后再调用WriteToDB进行写入。 12345678910func (s *StandAloneStorage) Write(ctx *kvrpcpb.Context, batch []storage.Modify) error &#123; // Your Code Here (1). var wb engine_util.WriteBatch for _, m := range batch &#123; wb.SetCF(m.Cf(), m.Key(), m.Value()) &#125; err := wb.WriteToDB(s.en.Kv) return err&#125; 当Modify.Data的类型为Delete时，没有Value成员，m.Value()会返回nil，在badger.Entry当中，Value成员为nil时也表示删除，所以上述代码能够正确处理添加和删除两种操作。 func ReaderReader方法需返回一个实现StorageReader接口的类，该接口包含GetCF、IterCF和Close三个方法。此处我定义了一个名为Reader的类实现该接口。 engine_util包中的GetCF函数和NewCFIterator函数可用于实现前两个方法，这两个函数分别需要传入badger指针和badger.Txn指针，因此，我们的自定义Reader类，第一，需要包含StandAloneStorage成员，以访问badger；第二，需要包含badger.Txn成员，这个成员在IterCF方法中通过badger.NewTransaction函数进行创建。此外，为了在Close方法中关闭迭代器，我们还需要包含迭代器成员。综上所述，Reader类和Reader方法定义如下： 12345678910type Reader struct &#123; s *StandAloneStorage txn *badger.Txn it *engine_util.BadgerIterator&#125;func (s *StandAloneStorage) Reader(ctx *kvrpcpb.Context) (storage.StorageReader, error) &#123; // Your Code Here (1). return &amp;Reader&#123;s, nil, nil&#125;, nil&#125; GetCF方法和IterCF方法的实现参照前文。对于Close方法，需要执行关闭迭代器和丢弃txn两个操作。 12345678910111213141516171819func (r *Reader) GetCF(cf string, key []byte) ([]byte, error) &#123; val, _ := engine_util.GetCF(r.s.en.Kv, cf, key) return val, nil&#125;func (r *Reader) IterCF(cf string) engine_util.DBIterator &#123; r.txn = r.s.en.Kv.NewTransaction(false) r.it = engine_util.NewCFIterator(cf, r.txn) return r.it&#125;func (r *Reader) Close() &#123; if r.it != nil &#123; r.it.Close() &#125; if r.txn != nil &#123; r.txn.Discard() &#125;&#125; Raw API的实现func RawGet调用Reader.GetCF即可。需要注意的点是resp.NotFound成员必须进行赋值。 12345678910111213141516171819func (server *Server) RawGet(_ context.Context, req *kvrpcpb.RawGetRequest) (*kvrpcpb.RawGetResponse, error) &#123; // Your Code Here (1). reader, err := server.storage.Reader(nil) if err != nil &#123; return nil, err &#125; defer reader.Close() val, _ := reader.GetCF(req.GetCf(), req.GetKey()) resp := new(kvrpcpb.RawGetResponse) if val == nil &#123; resp.NotFound = true &#125; else &#123; resp.Value = val resp.NotFound = false &#125; return resp, nil&#125; func RawPutRawPutRequest仅包含一个请求，因此只需要创建一个长度为1的Modify切片放入请求，然后调用Write。 12345678910111213func (server *Server) RawPut(_ context.Context, req *kvrpcpb.RawPutRequest) (*kvrpcpb.RawPutResponse, error) &#123; // Your Code Here (1). // Hint: Consider using Storage.Modify to store data to be modified batch := make([]storage.Modify, 1) batch[0].Data = storage.Put&#123;Key: req.GetKey(), Value: req.GetValue(), Cf: req.GetCf()&#125; err := server.storage.Write(nil, batch) if err != nil &#123; return nil, err &#125; return nil, nil&#125; func RawDelete同RawPut。 12345678910111213func (server *Server) RawDelete(_ context.Context, req *kvrpcpb.RawDeleteRequest) (*kvrpcpb.RawDeleteResponse, error) &#123; // Your Code Here (1). // Hint: Consider using Storage.Modify to store data to be deleted batch := make([]storage.Modify, 1) batch[0].Data = storage.Delete&#123;Key: req.GetKey(), Cf: req.GetCf()&#125; err := server.storage.Write(nil, batch) if err != nil &#123; return nil, err &#125; return nil, nil&#125; func RawScan流程如下： 获得Reader 调用Reader.IterCF获得迭代器it 将迭代器it定位至req.StartKey处 创建切片，循环读取KV对放到切片末尾，直到KV对数量达到req.Limit，或者迭代器失效 返回响应 1234567891011121314151617181920212223242526func (server *Server) RawScan(_ context.Context, req *kvrpcpb.RawScanRequest) (*kvrpcpb.RawScanResponse, error) &#123; // Your Code Here (1). // Hint: Consider using reader.IterCF reader, err := server.storage.Reader(nil) if err != nil &#123; return nil, err &#125; defer reader.Close() it := reader.IterCF(req.GetCf()) it.Seek(req.StartKey) kvs := make([]*kvrpcpb.KvPair, 0) for i := 0; i &lt; int(req.GetLimit()) &amp;&amp; it.Valid(); i++ &#123; val, _ := it.Item().Value() var Kv kvrpcpb.KvPair if val != nil &#123; Kv = kvrpcpb.KvPair&#123;Key: it.Item().Key(), Value: val&#125; &#125; else &#123; Kv = kvrpcpb.KvPair&#123;Key: it.Item().Key()&#125; &#125; kvs = append(kvs, &amp;Kv) it.Next() &#125; return &amp;kvrpcpb.RawScanResponse&#123;Kvs: kvs&#125;, nil&#125; 容易出错的两个地方：一是没有reader没有关闭，二是迭代器没有先通过Seek方法定位到StartKey处。 错误与调试Engines的RaftDB留空导致Destroy Engines时无法访问nil.Close()。 没有设置RawGetResponse.NotFound RawGet的返回值问题当key not found时，RawGet算作正常返回，不应该返回error。 未判断迭代器是否有效 未将迭代器Seek到StartKey位置","tags":[{"name":"Go","slug":"Go","permalink":"https://starman-swa.github.io/tags/Go/"}],"categories":[{"name":"Go","slug":"Go","permalink":"https://starman-swa.github.io/categories/Go/"}]},{"title":"A Tour of Go学习笔记","date":"2021-07-29T07:29:10.000Z","path":"wiki/A-Tour-of-Go学习笔记/","text":"下载A Tour of Go本地中文版A Tour of Go的中文网页 https://tour.go-zh.org/ 提示隐私错误，无法访问，可安装本地版进行离线学习。 安装Go Downloads - The Go Programming Language (golang.org) 配置环境变量 Go有两个环境变量：$GOROOT和$GOPATH，前者是Go的安装目录，后者是Go的工作区目录。 设置代理 12go env -w GOPROXY=https://goproxy.cn,directset GO111MODULE=on 下载A Tour of Go中文版 1go get -u github.com/Go-zh/tour 运行 12cd D:\\Documents\\source\\go\\pkg\\mod\\github.com\\!go-zh\\tour@v0.0.0-20210601082505-f4baf0dba327go run . Basics包、变量和函数包Go的主程序从package main中的func main开始执行。 导入12345678910package mainimport ( &quot;fmt&quot; &quot;math&quot;)func main() &#123; fmt.Printf(&quot;Now you have %g problems.\\n&quot;, math.Sqrt(7))&#125; 使用import语句导入包，包名要加引号，括号实现多个包的导入，也可通过多条单独的import语句实现。 导入包中的子函数时用”&#x2F;“作为分隔符： 1234...import &quot;math/rand&quot;...fmt.Println(&quot;My favorite number is&quot;, rand.Intn(10)) 导出名导出名首字母必须大写，例如math.Pi。 函数函数定义格式如下，注意类型在变量名之后： 12345func add(x int, y int) int &#123; return x + y&#125; x int, y int可简写成x, y int。 多值返回使用括号括起来： 123func swap(x, y string) (string, string) &#123; return y, x&#125; 命名返回值Go的返回值能够被命名，可对返回值变量直接赋值，然后省略return语句后面的变量名。 12345func split(sum int) (x, y int) &#123; x = sum * 4 / 9 y = sum - x return&#125; 注意，return语句本身不能省略，只有无返回值的函数能够不写return语句。 变量var c, python, java bool 注意没有var i int, j bool这种写法 变量可在函数内声明，也可在函数外（包级别）声明。 函数内外声明的变量均进行了默认初始化。 变量的初始化12var i, j int = 1, 2 // 初始化必须在等号后面一次性写出var c, python, java = true, false, &quot;no!&quot; // 变量类型明确时，可不显式写出 注意不能var i = 1, j = 2。 短变量声明可用:=代替var声明：k := 3，但是:=不能在函数外使用。 基本类型 bool string int int8 int16 int32 int64 uint uint8 uint16 uint32 uint64 uintptr byte &#x2F;&#x2F; uint8 的别名 rune &#x2F;&#x2F; int32 的别名 &#x2F;&#x2F; 表示一个 Unicode 码点 float32 float64 complex64 complex128 int, uint 和 uintptr 在 32 位系统上通常为 32 位宽，在 64 位系统上则为 64 位宽。 零值未被初始化的变量会被赋值为0、false或””。 类型转换123var i int = 42var f float64 = float64(i)// 或者f := float64(i) Go要求显式类型转换。 类型推导当使用:=声明变量时，Go会根据右侧的变量类型进行类型推导。 常量1const Pi = 3.14 常量不能使用:=声明。 数值常量1234567const ( // 将 1 左移 100 位来创建一个非常大的数字 // 即这个数的二进制是 1 后面跟着 100 个 0 Big = 1 &lt;&lt; 100 // 再往右移 99 位，即 Small = 1 &lt;&lt; 1，或者说 Small = 2 Small = Big &gt;&gt; 99) 数值常量是高精度的值，一个未指定类型的常量由上下文来决定其类型。注意到可用括号同时声明多个常量。 流程控制语句：for、if、else、switch和deferfor123for i := 0; i &lt; 10; i++ &#123; sum += i&#125; for是Go中唯一的循环结构。for语句无需使用小括号，而花括号是必须的。for循环的初始化语句和后置语句是可选的。 for是Go中的”while“123for sum &lt; 100 &#123; sum += sum&#125; for可以只写循环条件部分，省略分号，此时相当于while。 if与for类似，无需小括号，但必须使用花括号。 if的简短语句123if v := math.Pow(x, n); v &lt; lim &#123; return v&#125; if可以在判断条件之前执行一个简单的语句，适用于对某个变量进行赋值之后需要立即进行判断的情况。 注意：同for循环类似，此处声明的变量只在if中可见，if之外不可见。 if和else同样可以使用简短的声明语句，且声明的变量在所有else分支中均可见。else if当中也可以继续声明变量。 练习：循环和函数牛顿法实现平方根函数： 1234567891011121314151617181920package mainimport ( &quot;fmt&quot;)func Sqrt(x float64) float64 &#123; z := 1.0 times := 10 fmt.Println(&quot;x ==&quot;, x) for count := 0; count &lt; times; count++ &#123; z -= (z * z - x) / (2 * z) fmt.Println(&quot;Times:&quot;, count, &quot;result:&quot;, z) &#125; return z&#125;func main() &#123; fmt.Println(Sqrt(2))&#125; switch12345678910switch os := runtime.GOOS; os &#123;case &quot;darwin&quot;: fmt.Println(&quot;OS X.&quot;)case &quot;linux&quot;: fmt.Println(&quot;Linux.&quot;)default: // freebsd, openbsd, // plan9, windows... fmt.Printf(&quot;%s.\\n&quot;, os)&#125; Go中的switch特征： case后面默认带了break，除非以fallthrough语句结束 case值无需为常量，不必为整数 switch的求值顺序switch从上到下逐个匹配case语句，匹配成功时停止。对于如下语句，在i==0时函数f()不会被调用： 1234switch i &#123;case 0:case f():&#125; 没有条件的switch相当于switch true，即case当中的求值结果为true时执行。可以用于代替复杂的if-else。 deferdefer语句会将函数推迟到外层函数返回后执行。注意，参数会被立即求值，但函数会被推迟调用。 12345func main() &#123; defer fmt.Println(&quot;world&quot;) fmt.Println(&quot;hello&quot;)&#125; defer栈被推迟调用的函数会被压入一个栈中，外层函数返回时，依次弹出并访问栈顶元素。 123456789func main() &#123; fmt.Println(&quot;counting&quot;) for i := 0; i &lt; 10; i++ &#123; defer fmt.Println(i) &#125; fmt.Println(&quot;done&quot;)&#125; 更多类型：struct、slice和映射指针声明指针：var p *int 使用指针： 1234i := 42p = &amp;ifmt.Println(*p)*p = 21 但是，与C语言不同，Go没有指针运算，不能对指针进行p++之类的操作。 结构体12345678type Vertex struct &#123; X int Y int&#125; // 声明方式为type name struct &#123;&#125;func main() &#123; fmt.Println(Vertex&#123;1, 2&#125;) // 匿名struct&#125; 结构体字段123v := Vertex&#123;1, 2&#125; // 使用匿名struct进行初始化，自动进行类型推断v.X = 4 // 使用点访问成员fmt.Println(v.X) 结构体指针123456789func main() &#123; v := Vertex&#123;1, 2&#125; p := &amp;v // 简单声明 var q *Vertex // 显式声明 q = &amp;v p.X = 1e9 fmt.Println(v) fmt.Println(*q)&#125; 12&#123;1000000000 2&#125;&#123;1000000000 2&#125; 结构体文法结构体文法通过直接列出字段的值来分配一个结构体（即匿名结构体），可以通过“字段名+冒号”来列出部分字段，且无需按顺序列出，例如可执行语句v2 := Vertex&#123;X: 1&#125;，此时Y: 0被隐式地赋予。 数组类型说明T[n]表示含有n个T类型元素的数组，如var a [10]int。数组的长度是类型的一部分，不能修改。数组声明时会分配空间，所有元素会被默认初始化。 12var a [2]intfmt.Println(a[0], a[1]) 10 0 切片切片也是一个变量，类型说明[]T表示T类型的切片。切片的范围由一个左闭右开区间指定：var s []int = primes[1:4]。 切片就像数组的引用切片并不存储数据，更改切片元素会修改底层数组中对应的元素。 切片文法切片文法类似于一个没有长度的数组文法。注意切片的类型说明符中不能带长度。 []bool&#123;true, true, false&#125;语句创建了一个数组，然后构建了一个引用它的切片。 切片的默认行为进行切片时，可省略上下界。以下切片是等价的： 1234a[0:10]a[:10]a[0:]a[:] 切片的长度和容量切片的长度就是它所包含元素的个数；切片的容量是从它的第一个元素开始数，到其底层数组末尾的个数。 切片s的长度和容量可通过表达式len(s)和cap(s)来获取。 只要具有足够的容量，可以通过重新切片来扩展一个切片。 123456789101112131415161718192021222324package mainimport &quot;fmt&quot;func main() &#123; s := []int&#123;2, 3, 5, 7, 11, 13&#125; printSlice(s) // 截取切片使其长度为 0 s = s[:0] printSlice(s) // 拓展其长度 s = s[:4] printSlice(s) // 舍弃前两个值 s = s[2:] printSlice(s)&#125;func printSlice(s []int) &#123; fmt.Printf(&quot;len=%d cap=%d %v\\n&quot;, len(s), cap(s), s)&#125; 1234len=6 cap=6 [2 3 5 7 11 13]len=0 cap=6 []len=4 cap=6 [2 3 5 7]len=2 cap=4 [5 7] 可见截取一个切片的前部时，切片的容量不变。但截取切片后部，即舍弃切片前部时，切片的容量会减小。 nil切片切片的零值是nil。 nil 切片的长度和容量为 0 且没有底层数组。 声明nil切片：var s []int。 用make创建切片make函数会分配一个元素为零值的数组并返回一个引用了它的切片： 1a := make([]int, 5) // len(a)=cap(a)=5 要指定它的容量，需向make传入第三个参数： 1234b := make([]int, 0, 5) // len(b)=0, cap(b)=5b = b[:cap(b)] // len(b)=5, cap(b)=5b = b[1:] // len(b)=4, cap(b)=4 注意，二次切片的len有可能比父切片大，例如： 12345678910111213func main() &#123; a := make([]int, 5) printSlice(&quot;a&quot;, a) b := make([]int, 0, 5) printSlice(&quot;b&quot;, b) c := b[:2] printSlice(&quot;c&quot;, c) d := c[2:5] printSlice(&quot;d&quot;, d)&#125; 1234a len=5 cap=5 [0 0 0 0 0]b len=0 cap=5 []c len=2 cap=5 [0 0]d len=3 cap=3 [0 0 0] c的长度只有2，但是d取了一个长度为3的切片，此时可以越过c的长度，继续从底层数组中取第三个元素。 切片的切片12345678910111213// 创建一个井字板（经典游戏）board := [][]string&#123; []string&#123;&quot;_&quot;, &quot;_&quot;, &quot;_&quot;&#125;, []string&#123;&quot;_&quot;, &quot;_&quot;, &quot;_&quot;&#125;, []string&#123;&quot;_&quot;, &quot;_&quot;, &quot;_&quot;&#125;,&#125;// 两个玩家轮流打上 X 和 Oboard[0][0] = &quot;X&quot;board[2][2] = &quot;O&quot;board[1][2] = &quot;X&quot;board[1][0] = &quot;O&quot;board[0][2] = &quot;X&quot; 向切片追加元素func append(s []T, vs ...T) []T s为待追加的切片，vs为要追加的值，返回新切片。当 s 的底层数组太小，不足以容纳所有给定的值时，它就会分配一个更大的数组。返回的切片会指向这个新分配的数组。 注意，关于追加值是否会改变原底层数组的值，经过我的测试，分为两种情况： 如果底层数组容量足够，则追加值直接覆盖底层数组原来的值 如果底层数组容量不足，则不会改变原数组，而会分配一个新的数组，切片指向新数组 Rangefor 循环的 range 形式可遍历切片或映射。 当使用 for 循环遍历切片时，每次迭代都会返回两个值。第一个值为当前元素的下标，第二个值为该下标所对应元素的一份副本。 1234567var pow = []int&#123;1, 2, 4, 8, 16, 32, 64, 128&#125;func main() &#123; for i, v := range pow &#123; fmt.Printf(&quot;2**%d = %d\\n&quot;, i, v) &#125;&#125; Go中不允许存在声明但未使用的变量，若不需要使用下标或者元素值，可以用下划线代替变量名忽略它；如果只需要使用下标，可以直接不写第二个变量和逗号。 123for i, _ := range powfor _, value := range powfor i := range pow 当使用range遍历映射时，第一个值为key，第二个值为value。 练习：切片创建一个二维切片，作为存储图像灰度值的矩阵，然后依次填入每个灰度值。 1234567891011121314func Pic(dx, dy int) [][]uint8 &#123; slice := make([][]uint8, dy) for i := 0; i &lt; dy; i++ &#123; slice[i] = make([]uint8, dx) // (*) &#125; for i := 0; i &lt; dy; i++ &#123; for j := 0; j &lt; dx; j++ &#123; slice[i][j] = uint8(i) ^ uint8(j) &#125; &#125; return slice&#125; 我一开始把(*)行的=写成了:=，出现报错，原因是slice[i]是一个已存在的元素，为nil切片，而:=只能用于声明新的变量。 映射（map）映射将key映射到value。零值为nil，既没有key，也不能添加key。make函数会返回给定类型的映射，并将其初始化备用。 12345678910111213type Vertex struct &#123; Lat, Long float64&#125;var m map[string]Vertex // 方括号中为key的类型，方括号后面为value的类型func main() &#123; m = make(map[string]Vertex) m[&quot;Bell Labs&quot;] = Vertex&#123; 40.68433, -74.39967, &#125; fmt.Println(m[&quot;Bell Labs&quot;])&#125; 映射的文法映射的文法与结构体相似，不过必须有键名。 12345678var m = map[string]Vertex&#123; &quot;Bell Labs&quot;: Vertex&#123; 40.68433, -74.39967, &#125;, &quot;Google&quot;: Vertex&#123; 37.42202, -122.08408, &#125;,&#125; 以上为映射初始化方法，key和value之间用冒号隔开，不同KV对之间用逗号隔开，最后一个也必须有逗号。 ”Vertex“也可以省略。 修改映射1234567m[key] = elem // 插入或修改元素elem = m[key] // 获取元素delete(m, key) // 删除元素elem, ok = m[key] // 通过双赋值检测某个key是否存在// 若key在m中，ok为true；否则，ok为false// 若key不在映射中，那么elem是该映射元素类型的零值elem, ok := m[key] // 若elem或ok还未声明，可以使用短变量声明 练习：映射统计词频，保存到map中，可使用strings.Fields函数分割字符串。 12345678func WordCount(s string) map[string]int &#123; m := make(map[string]int) words := strings.Fields(s) for _, word := range words &#123; m[word]++ &#125; return m&#125; 函数值函数也是值，可以作为函数的参数或返回值。也可以用:=声明一个函数变量。 12345678910111213func compute(fn func(float64, float64) float64) float64 &#123; return fn(3, 4)&#125;func main() &#123; hypot := func(x, y float64) float64 &#123; return math.Sqrt(x*x + y*y) &#125; fmt.Println(hypot(5, 12)) fmt.Println(compute(hypot)) fmt.Println(compute(math.Pow))&#125; 函数的闭包Go 函数可以是一个闭包。闭包是一个函数值，它引用了其函数体之外的变量。该函数可以访问并赋予其引用的变量的值，换句话说，该函数被这些变量“绑定”在一起。 1234567891011121314151617func adder() func(int) int &#123; sum := 0 return func(x int) int &#123; sum += x return sum &#125;&#125;func main() &#123; pos, neg := adder(), adder() for i := 0; i &lt; 10; i++ &#123; fmt.Println( pos(i), neg(-2*i), ) &#125;&#125; pos和neg各为一个闭包，都包含一个sum变量，初值为0。每次调用pos时，sum变量的值加i，然后输出sum。 可以把函数闭包理解成类的静态函数，sum为静态变量。 练习：斐波那契闭包1234567891011121314151617181920212223// 返回一个“返回int的函数”func fibonacci() func() int &#123; a, b := 0, 1 count := 0 return func() int &#123; count++ if count == 1 &#123; return 0 &#125; else if count == 2 &#123; return 1 &#125; else &#123; a, b = b, a + b return b &#125; &#125;&#125;func main() &#123; f := fibonacci() for i := 0; i &lt; 10; i++ &#123; fmt.Println(f()) &#125;&#125; 若count为1或2，直接返回第一项或第二项的值；否则，计算当前项的值，然后返回。 Methods and interfaces方法和接口方法Go没有类，但是可以为结构体定义方法。方法是一类带特殊的接收者参数的函数。 例如，为Vertex定义方法： 12345678func (v Vertex) Abs() float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func main() &#123; v := Vertex&#123;3, 4&#125; fmt.Println(v.Abs())&#125; 也可为基本类型定义方法，不过要先定义类型别名，例如：type MyFloat float64，然后就可以为MyFloat类型定义方法。 指针接收者注意，上述接收者是值接收者，只能用于访问；如果要修改结构体的成员，需要使用指针接收者：func (v *Vertex) Scale(f float64) &#123;&#125; 方法与指针重定向调用指针接收者方法时，可以通过变量调用，也可以通过指针调用： 1234var v Vertexv.Scale(5) // OKp := &amp;vp.Scale(10) // OK 选择值或指针作为接收者使用指针接收者的原因有二： 首先，方法能够修改其接收者指向的值。 其次，这样可以避免在每次调用方法时复制该值。若值的类型为大型结构体时，这样做会更加高效。 通常来说，所有给定类型的方法都应该有值或指针接收者，但并不应该二者混用。 接口接口类型是由一组方法签名定义的集合，接口类型的变量可以保存任何实现了这些方法的值。 123456789101112131415// 定义接口type Abser interface &#123; Abs() float64&#125;// 实现Absfunc (f MyFloat) Abs() float64 &#123;...&#125; // 接收者为值func (v *Vertex) Abs() float64 &#123;...&#125; // 接收者为指针var a Abser // 定义接口变量f := MyFloat(-math.Sqrt2)v := Vertex&#123;3, 4&#125;a = f // a MyFloat 实现了 Absera = &amp;v // a *Vertex 实现了 Absera = v // a Vertex 未实现 Abser，错误！ 此处要注意，当只有指针实现了方法时，接口变量也只能用指针赋值。 接口与隐式实现当一个类型实现了接口的所有方法时，它就实现了该接口，无需显式声明即可将该类型的变量直接赋值给接口变量。 隐式接口从接口的实现中解耦了定义，这样接口的实现可以出现在任何包中，无需提前准备。 因此，也就无需在每一个实现上增加新的接口名称，这样同时也鼓励了明确的接口定义。 接口值接口也是值，可作为函数的参数或返回值。 在内部，接口值可以看作包含值和具体类型的元组：(value, type)。接口值保存了一个具体底层类型的具体值。接口值调用方法时会执行其底层类型的同名方法。 底层值为nil的接口值即使接口内的具体值为nil，方法仍然会被nil接收者调用。 我们可以在方法中先判断接受者是否为空： 1234567func (t *T) M() &#123; if t == nil &#123; fmt.Println(&quot;&lt;nil&gt;&quot;) return &#125; fmt.Println(t.S)&#125; 执行下列代码时，控制台打印： 1234var i Ivar t *Ti = ti.M() nil接口值nil 接口值既不保存值也不保存具体类型。 为 nil 接口调用方法会产生运行时错误，因为接口的元组内并未包含能够指明该调用哪个具体方法的类型。 空接口指定了0个方法的接口为空接口： interface &#123;&#125; 空接口可以保存任何类型的值，因为任何类型的值都至少实现了0个接口。 空接口被用来处理未知类型的值。 1234567891011121314func main() &#123; var i interface&#123;&#125; describe(i) i = 42 describe(i) i = &quot;hello&quot; describe(i)&#125;func describe(i interface&#123;&#125;) &#123; fmt.Printf(&quot;(%v, %T)\\n&quot;, i, i)&#125; 类型断言类型断言提供了访问接口值底层具体值的方式。类型断言的语法与判断map中是否存在某个key非常相似。 12t := i.(T) // 若接口i保存了类型T，则将其赋值给t，否则触发一个panict, ok := i.(T) // ok为false时，t为零值，不会触发panic 类型选择类型选择使用switch-case语句，从几个类型断言中选择分支： 12345switch v := i.(type) &#123;case T:case S:default:&#125; 其声明语法与类型断言类似，不过具体类型值换成了type。当匹配成功时，变量v会被赋值为相应类型的值（是具体类型，不是接口）。 Stringer123type Stringer interface &#123; String() string&#125; Stringer接口中的String函数规定了变量被fmt.Println函数打印的格式。 练习：Stringer为IP地址实现Stringer接口。注意，IP地址是用byte类型存储，首先要将其转换成int，再将int使用strconv.Itoa转换成string，不能一步到位直接byte转string，因为byte中存储的不是ASCII码。 12345678910111213141516171819202122232425262728293031package mainimport ( &quot;fmt&quot; &quot;strconv&quot;)type IPAddr [4]byte// TODO: 给 IPAddr 添加一个 &quot;String() string&quot; 方法func (ip IPAddr) String() string &#123; ip_str := &quot;&quot; for i := 0; i &lt; 4; i++ &#123; ip_str += strconv.Itoa(int(ip[i])) if i != 3 &#123; ip_str += &quot;.&quot; &#125; &#125; return ip_str&#125;func main() &#123; hosts := map[string]IPAddr&#123; &quot;loopback&quot;: &#123;127, 0, 0, 1&#125;, &quot;googleDNS&quot;: &#123;8, 8, 8, 8&#125;, &#125; for name, ip := range hosts &#123; fmt.Printf(&quot;%v: %v\\n&quot;, name, ip) &#125;&#125; 错误错误error也是一个接口。同Stringer一样，Error函数返回的字符串也用于fmt包打印时。 123type error interface &#123; Error() string&#125; 通常函数会返回一个error值，应判断其是否为nil： 1i, err := strconv.Atoi(&quot;42&quot;) 练习：错误修改之前的Sqrt函数，当输入值为负时返回一个error。 1234567891011121314151617181920212223242526272829303132package mainimport ( &quot;fmt&quot;)type ErrNegativeSqrt float64 // 将float64定义为错误类型func (e ErrNegativeSqrt) Error() string &#123; // ErrNegativeSqrt类型实现了error接口，因此它是一个error类型 str := &quot;cannot Sqrt negative number: &quot; + fmt.Sprintf(&quot;%f&quot;, float64(e)) // 注意Sprintf函数的使用 return str&#125;func Sqrt(x float64) (float64, error) &#123; if x &lt; 0 &#123; var err ErrNegativeSqrt = ErrNegativeSqrt(x) // 创建一个错误类型变量，将x值赋值给它 return x, err &#125; z := 1.0 times := 10 for count := 0; count &lt; times; count++ &#123; z -= (z * z - x) / (2 * z) &#125; return z, nil&#125;func main() &#123; fmt.Println(Sqrt(2)) fmt.Println(Sqrt(-2))&#125; Readerio.Reader接口中有一个Read方法：func (T) Read(b []byte) (n int, err error) 用于从类型T的变量读取前n个字节，存放到切片b中。在遇到输入流的结尾时，它会返回一个io.EOF错误。 练习：Reader实现一个无限字符流’A’。可以通过len获取切片长度，然后将其填满。 1234567// TODO: 给 MyReader 添加一个 Read([]byte) (int, error) 方法func (r MyReader) Read(slice []byte) (int, error) &#123; for i := 0; i &lt; len(slice); i++ &#123; slice[i] = &#x27;A&#x27; &#125; return len(slice), nil&#125; 练习：rot13Reader1234567func (rd rot13Reader) Read(slice []byte) (n int, err error) &#123; n, err = rd.r.Read(slice) for i := 0; i &lt; n; i++ &#123; slice[i] = rot13(slice[i]) &#125; return&#125; 图像1234567package imagetype Image interface &#123; ColorModel() color.Model Bounds() Rectangle // 图像边界 At(x, y int) color.Color // 访问某个像素点&#125; 练习：图像使用image接口实现图像。 1234567891011121314151617181920212223242526package mainimport ( &quot;golang.org/x/tour/pic&quot; &quot;image/color&quot; &quot;image&quot;)type Image struct&#123;&#125;func (img Image) ColorModel() color.Model &#123; return color.RGBAModel&#125;func (img Image) Bounds() image.Rectangle &#123; return image.Rect(0, 0, 800, 600)&#125;func (img Image) At(x, y int) color.Color &#123; return color.RGBA&#123;(uint8)(x*y), (uint8)(x*y), 255, 255&#125;&#125;func main() &#123; m := Image&#123;&#125; pic.ShowImage(m)&#125; Concurrency并发Go程Go程（goroutine）是由 Go 运行时管理的轻量级线程。 go f(x, y, z)创建一个新的goroutine并执行f函数。 goroutine之间共享内存。 信道123ch := make(chan int) // 创建信道ch &lt;- v // 将 v 发送至信道 ch。v := &lt;-ch // 从 ch 接收值并赋予 v。 默认情况下，信道的发送和接受是阻塞的。 123456789101112131415161718func sum(s []int, c chan int) &#123; sum := 0 for _, v := range s &#123; sum += v &#125; c &lt;- sum // 将和送入 c&#125;func main() &#123; s := []int&#123;7, 2, 8, -9, 4, 0&#125; c := make(chan int) go sum(s[:len(s)/2], c) go sum(s[len(s)/2:], c) x, y := &lt;-c, &lt;-c // 从 c 中接收 fmt.Println(x, y, x+y)&#125; 注意，两次&lt;-c并不代表信道可以存放多个值。创建两个goroutine之后，主线程在接受处阻塞。每当一个goroutine完成计算，向信道写入值时，主进程立即读出，此时另外一个goroutine才能再进行写入。 带缓冲的信道ch := make(chan int, 100)创建了一个大小为100的信道。仅当缓冲区填满时，向其发送数据才会阻塞。当缓冲区为空时，接收方会阻塞。 range和close发送者可以通过close关闭信道，表示没有需要发送的值了。接收者可以通过第二个参数测试信道是否被关闭：v, ok := &lt;-ch 循环for i := range c会从信道不断接收值，直到它被关闭。 只有发送者能关闭信道，接收者不能。向一个已经关闭的信道发送数据会引发panic。 注意：信道与文件不同，通常情况下无需关闭它们。只有在必须告诉接收者不再有需要发送的值时才有必要关闭，例如终止一个 range 循环。 select语句select 语句使一个 Go 程可以等待多个通信操作。 select 会阻塞到某个分支可以继续执行为止，这时就会执行该分支。当多个分支都准备好时会随机选择一个执行。 123456789101112131415161718192021222324func fibonacci(c, quit chan int) &#123; x, y := 0, 1 for &#123; select &#123; case c &lt;- x: x, y = y, x+y case &lt;-quit: fmt.Println(&quot;quit&quot;) return &#125; &#125;&#125;func main() &#123; c := make(chan int) quit := make(chan int) go func() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Println(&lt;-c) &#125; quit &lt;- 0 &#125;() // 学习此处的匿名函数写法 fibonacci(c, quit)&#125; 默认选择当select中的其他分支都没有准备好时，执行default分支。用于避免程序阻塞。 练习：等价二叉查找树123456789101112131415161718192021222324252627282930313233343536package mainimport ( &quot;fmt&quot; &quot;golang.org/x/tour/tree&quot;)// Walk 步进 tree t 将所有的值从 tree 发送到 channel ch。func Walk(t *tree.Tree, ch chan int) &#123; if (t != nil) &#123; Walk(t.Left, ch) ch &lt;- t.Value Walk(t.Right, ch) &#125;&#125;// Same 检测树 t1 和 t2 是否含有相同的值。func Same(t1, t2 *tree.Tree) bool &#123; ch1, ch2 := make(chan int), make(chan int) go Walk(t1, ch1) go Walk(t2, ch2) for i := 0; i &lt; 10; i++ &#123; v1 := &lt;-ch1 v2 := &lt;-ch2 if v1 != v2 &#123; return false &#125; &#125; return true&#125;func main() &#123; t1 := tree.New(1) t2 := tree.New(1) fmt.Println(Same(t1, t2))&#125; sync.MutexMutex变量可进行Lock和Unlock。可使用defer保证互斥锁一定会被解锁。学习下列例子中defer的用法： 1234567// Value 返回给定 key 的计数器的当前值。func (c *SafeCounter) Value(key string) int &#123; c.mux.Lock() // Lock 之后同一时刻只有一个 goroutine 能访问 c.v defer c.mux.Unlock() return c.v[key]&#125; 练习：Web爬虫123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106package mainimport ( &quot;fmt&quot; &quot;sync&quot;)type Fetcher interface &#123; // Fetch 返回 URL 的 body 内容，并且将在这个页面上找到的 URL 放到一个 slice 中。 Fetch(url string) (body string, urls []string, err error)&#125;var crawled map[string]bool = make(map[string]bool)var mutex sync.Mutex// Crawl 使用 fetcher 从某个 URL 开始递归的爬取页面，直到达到最大深度。func Crawl(url string, depth int, fetcher Fetcher, ch chan bool) &#123; // TODO: 并行的抓取 URL。 // TODO: 不重复抓取页面。 // fmt.Println(url, depth) if depth &lt;= 0 &#123; ch &lt;- true return &#125; body, urls, err := fetcher.Fetch(url) if err != nil &#123; fmt.Println(err) ch &lt;- true return &#125; mutex.Lock() if (crawled[url] == false) &#123; crawled[url] = true mutex.Unlock() fmt.Printf(&quot;found: %s %q\\n&quot;, url, body) subCh := make(chan bool) for _, u := range urls &#123; go Crawl(u, depth-1, fetcher, subCh) &#125; for i := 0; i &lt; len(urls); i++ &#123; &lt;- subCh &#125; &#125; else &#123; mutex.Unlock() &#125; ch &lt;- true return&#125;func main() &#123; ch := make(chan bool) go Crawl(&quot;https://golang.org/&quot;, 4, fetcher, ch) &lt;- ch&#125;// fakeFetcher 是返回若干结果的 Fetcher。type fakeFetcher map[string]*fakeResulttype fakeResult struct &#123; body string urls []string&#125;func (f fakeFetcher) Fetch(url string) (string, []string, error) &#123; if res, ok := f[url]; ok &#123; return res.body, res.urls, nil &#125; return &quot;&quot;, nil, fmt.Errorf(&quot;not found: %s&quot;, url)&#125;// fetcher 是填充后的 fakeFetcher。var fetcher = fakeFetcher&#123; &quot;https://golang.org/&quot;: &amp;fakeResult&#123; &quot;The Go Programming Language&quot;, []string&#123; &quot;https://golang.org/pkg/&quot;, &quot;https://golang.org/cmd/&quot;, &#125;, &#125;, &quot;https://golang.org/pkg/&quot;: &amp;fakeResult&#123; &quot;Packages&quot;, []string&#123; &quot;https://golang.org/&quot;, &quot;https://golang.org/cmd/&quot;, &quot;https://golang.org/pkg/fmt/&quot;, &quot;https://golang.org/pkg/os/&quot;, &#125;, &#125;, &quot;https://golang.org/pkg/fmt/&quot;: &amp;fakeResult&#123; &quot;Package fmt&quot;, []string&#123; &quot;https://golang.org/&quot;, &quot;https://golang.org/pkg/&quot;, &#125;, &#125;, &quot;https://golang.org/pkg/os/&quot;: &amp;fakeResult&#123; &quot;Package os&quot;, []string&#123; &quot;https://golang.org/&quot;, &quot;https://golang.org/pkg/&quot;, &#125;, &#125;,&#125; 信道的作用在于等待所有goroutine完成后再退出本线程，相当于pthread_join。","tags":[{"name":"Go","slug":"Go","permalink":"https://starman-swa.github.io/tags/Go/"}],"categories":[{"name":"Go","slug":"Go","permalink":"https://starman-swa.github.io/categories/Go/"}]},{"title":"Prim算法 vs Dijkstra算法","date":"2021-07-25T11:32:43.000Z","path":"wiki/Prim算法-vs-Dijkstra算法/","text":"Prim算法用于求最小生成树，Dijkstra算法用于求单源最短路径。两者的用途不同，但算法实现非常类似，都采用了贪心算法，都是将顶点从一个集合加到另一个集合当中。但不同的是两者的选点标准：假设已加入的点集为U，未加入的点集为V。Prim算法在V中选取与U中任意顶点直接距离最短的那个顶点加入U，Dijkstra算法选取V中与初始顶点距离最短的那个顶点加入U。","tags":[{"name":"图论","slug":"图论","permalink":"https://starman-swa.github.io/tags/%E5%9B%BE%E8%AE%BA/"}],"categories":[{"name":"算法","slug":"算法","permalink":"https://starman-swa.github.io/categories/%E7%AE%97%E6%B3%95/"}]},{"title":"0-1背包问题笔记","date":"2021-07-16T12:13:36.000Z","path":"wiki/0-1背包问题笔记/","text":"一、原始版本0-1背包问题的原始版本为： 有N件物品和一个最大容纳重量为W的背包。第i件物品的重量是weights[i]，价值是values[i] ，每件物品只能用一次，问将哪些物品装入背包之后物品的总价值最大。 通用的解题模板为：设计一个二维数组dp[N+1][W+1]，使用两层循环遍历，最后返回二维数组的最后一个值，代码如下。 1234567891011121314vector&lt;vector&lt;int&gt;&gt; dp(N + 1, vector&lt;int&gt; (W + 1, 0));// 此处dp[i][j]的含义为：遍历完前i个物体之后，背包中所装物体重量不超过W时的物品的总最大价值for (int i = 1; i &lt;= N; ++i) &#123; for (int w = 0; w &lt;= W; ++w) &#123; // 注意weights与values访问时下标i需要减去1，因为i取值是1～N，而这两个数组的下标取值是0～N-1 dp[i][w] = dp[i - 1][w]; // 不选第i个物品 if (w &gt;= weights[i - 1]) &#123; dp[i][w] = max(dp[i][w], dp[i - 1][w - weights[i - 1]] + values[i - 1]); // 选第i个物品 &#125; &#125;&#125;return dp[N][W]; 上述代码是我刚刚总结出来的，还没测试过，因为实际做题中遇到的都是原始题目的变体，代码实现上会有细微的差异，很容易转不过弯来。 可能需要修改的地方包括但不限于： 数组第一维的大小（是否需要+1） 数组第二维的大小 外层循环的遍历范围 是否需要初始化dp[0]、如何初始化 返回值的选取 dp[i][w]选用的是max还是min，还是bool值 二、“恰好”版：LeetCode 416 分割等和子集 给你一个 只包含正整数 的 非空 数组 nums 。请你判断是否可以将这个数组分割成两个子集，使得两个子集的元素和相等。 首先进行映射： 物品&#x3D;&gt;数 物品重量&#x3D;&gt;数值大小 物品总价值&#x3D;&gt;并不是一个求和结果，而是一个bool值，表示是否存在一种取法，使得物体总重量为该值 问题转换为：有nums.size()个物品，其重量为nums[i]，每个物品可放入背包也可不放入背包，求是否存在某一种取法，使得背包内的物品总重量恰好为sum(nums) &#x2F; 2。 代码实现： 123456789101112131415161718192021bool canPartition(vector&lt;int&gt;&amp; nums) &#123; int sum = 0; for (int i = 0; i &lt; nums.size(); ++i) &#123; sum += nums[i]; &#125; if (sum % 2) &#123; return false; &#125; vector&lt;vector&lt;int&gt;&gt; dp(nums.size(), (vector&lt;int&gt; (sum + 1, 0))); dp[0][nums[0]] = 1; dp[0][0] = 1; for (int i = 1; i &lt; nums.size(); ++i) &#123; for (int w = 0; w &lt;= sum / 2; ++w) &#123; if (dp[i - 1][w] || (w &gt;= nums[i]) &amp;&amp; dp[i - 1][w - nums[i]]) &#123; dp[i][w] = 1; &#125; &#125; &#125; return dp[nums.size() - 1][sum / 2];&#125; 代码细节： dp[i][j]的含义为：遍历完前i个物体之后，是否存在背包重量恰好为j的情况 数组第一维大小不需要加1，下标从0开始，遍历时跳过第0个 dp[0]需要进行初始化。两行初始化语句表示：遍历完第一个物体之后，背包容量要么为0，要么为第一个物体的重量 dp[i][w]的求法：只要取第i个或者不取第i个这两种取法的其中一种是合法的，dp[i][j]就为真 内层循环需遍历到num &#x2F; 2 三、“恰好”版：LeetCode 1049 最后一块石头的重量 有一堆石头，用整数数组 stones 表示。其中 stones[i] 表示第 i 块石头的重量。 每一回合，从中选出任意两块石头，然后将它们一起粉碎。假设石头的重量分别为 x 和 y，且 x &lt;&#x3D; y。那么粉碎的可能结果如下： 如果 x &#x3D;&#x3D; y，那么两块石头都会被完全粉碎；如果 x !&#x3D; y，那么重量为 x 的石头将会完全粉碎，而重量为 y 的石头新重量为 y-x。最后，最多只会剩下一块 石头。返回此石头 最小的可能重量 。如果没有石头剩下，就返回 0。 12345678910111213141516171819202122232425int lastStoneWeightII(vector&lt;int&gt;&amp; stones) &#123; int sum = 0; for (int i = 0; i &lt; stones.size(); ++i) &#123; sum += stones[i]; &#125; vector&lt;vector&lt;int&gt;&gt; dp(stones.size(), (vector&lt;int&gt; (sum + 1, 0))); dp[0][stones[0]] = 1; dp[0][0] = 1; for (int i = 1; i &lt; stones.size(); ++i) &#123; for (int w = 0; w &lt;= sum; ++w) &#123; if (dp[i - 1][w] || (w &gt;= stones[i]) &amp;&amp; dp[i - 1][w - stones[i]]) &#123; dp[i][w] = 1; &#125;; &#125; &#125; double sum_db = sum; double minVal = INT_MAX; for (int w = 0; w &lt;= sum; ++w) &#123; if (dp[stones.size() - 1][w]) minVal = min(minVal, abs(w - sum_db / 2)); &#125; return minVal * 2;&#125; 与上一题完全相同。这道题难在如何将题干转换成0-1背包问题。 四、双背包版：LeetCode 474 一和零 给你一个二进制字符串数组 strs 和两个整数 m 和 n 。 请你找出并返回 strs 的最大子集的大小，该子集中 最多 有 m 个 0 和 n 个 1 。 如果 x 的所有元素也是 y 的元素，集合 x 是集合 y 的 子集 。 我的思路非常朴素，多一个背包相当于给dp数组加一个维度，多套一层循环进行遍历。 这是我的错误解答： 1234567891011121314151617181920212223242526272829int findMaxFormIncorrectSolution(vector&lt;string&gt;&amp; strs, int m, int n) &#123; // 错误解答 vector&lt;vector&lt;int&gt;&gt; nums(strs.size(), vector&lt;int&gt; (2, 0)); for (int i = 0; i &lt; strs.size(); ++i) &#123; for (int j = 0; j &lt; strs[i].size(); ++j) &#123; if (strs[i][j] == &#x27;0&#x27;) ++nums[i][0]; else ++nums[i][1]; &#125; &#125; vector&lt;vector&lt;vector&lt;int&gt;&gt;&gt; dp(strs.size(), vector&lt;vector&lt;int&gt;&gt; (m + 1, vector&lt;int&gt; (n + 1, 0))); if (nums[0][0] &lt;= m &amp;&amp; nums[0][1] &lt;= n) dp[0][nums[0][0]][nums[0][1]] = 1; for (int i = 1; i &lt; strs.size(); ++i) &#123; for (int w0 = 0; w0 &lt;= m; ++w0) &#123; for (int w1 = 0; w1 &lt;= n; ++w1) &#123; int maxVal = 0; if (w0 &gt;= nums[i][0] &amp;&amp; w1 &gt;= nums[i][1]) &#123; maxVal = 1 + dp[i - 1][w0 - nums[i][0]][w1 - nums[i][1]]; &#125; maxVal = max(maxVal, dp[i - 1][w0][w1]); dp[i][w0][w1] = maxVal; &#125; &#125; &#125; return dp[strs.size() - 1][m][n];&#125; 错误原因在于：我受到了“恰好”版的影响，以为需要初始化dp[0]；但这道题更接近于原始版本，不需要初始化，数组第一维的长度相应地要加1，对nums数组的访问下标需要减1。因为题干提到了“最多 有 m 个 0 和 n 个 1 ”，所以dp数组的值表示的是背包重量不超过第二维和第三维时的最大价值，与原始版本题意相同，只是多了一维。 正确解答： 1234567891011121314151617181920212223242526int findMaxForm(vector&lt;string&gt;&amp; strs, int m, int n) &#123; vector&lt;vector&lt;int&gt;&gt; nums(strs.size(), vector&lt;int&gt; (2, 0)); for (int i = 0; i &lt; strs.size(); ++i) &#123; for (int j = 0; j &lt; strs[i].size(); ++j) &#123; if (strs[i][j] == &#x27;0&#x27;) ++nums[i][0]; else ++nums[i][1]; &#125; &#125; vector&lt;vector&lt;vector&lt;int&gt;&gt;&gt; dp(strs.size() + 1, vector&lt;vector&lt;int&gt;&gt; (m + 1, vector&lt;int&gt; (n + 1, 0))); for (int i = 1; i &lt;= strs.size(); ++i) &#123; for (int w0 = 0; w0 &lt;= m; ++w0) &#123; for (int w1 = 0; w1 &lt;= n; ++w1) &#123; int maxVal = 0; if (w0 &gt;= nums[i - 1][0] &amp;&amp; w1 &gt;= nums[i - 1][1]) &#123; maxVal = 1 + dp[i - 1][w0 - nums[i - 1][0]][w1 - nums[i - 1][1]]; &#125; maxVal = max(maxVal, dp[i - 1][w0][w1]); dp[i][w0][w1] = maxVal; &#125; &#125; &#125; return dp[strs.size()][m][n];&#125; 五、总结 原始版本：数组第一维长度N+1，外层循环从1遍历到N，无需初始化（准确地说应该是全部初始化为0） 恰好版本：数组第一维长度N，外层循环从1遍历到N-1，需初始化dp[0]，把恰好取第一个物体和不取第一个物体两种情况考虑进去 双背包版本：在上述基础上，给数组加一个维度 如果实在不想微调第一维的下标，想统一前两种情况，那么在原始版本当中，需要将dp[0][j], j &gt;&#x3D; weights[0]初始化为values[0]，之后就可以用”恰好“版的方式进行遍历。","tags":[{"name":"动态规划","slug":"动态规划","permalink":"https://starman-swa.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"}],"categories":[{"name":"算法","slug":"算法","permalink":"https://starman-swa.github.io/categories/%E7%AE%97%E6%B3%95/"}]},{"title":"我的实用软件清单","date":"2021-07-10T08:35:24.000Z","path":"wiki/我的实用软件清单/","text":"我的电脑上装了很多奇奇怪怪的小工具，今天做一个总结，以供查阅。 一、系统工具类DiskInternals Linux Reader：在Windows下访问Linux文件系统官网：Access to Ext 2&#x2F;3&#x2F;4, HFS and ReiserFS from Windows| DiskInternals 免费版只支持保存文件，收费版能够mount to system。 DiskGenius：磁盘分区管理软件官网：数据恢复软件,硬盘分区工具,系统备份软件 - DiskGenius官方网站 有一次帮朋友重装系统的时候不小心留了一片剩余空间，最后用这个工具合并的。 BestTrace：路由追踪官网：BestTrace 客户端_专业的 IP 地址库_IPIP.NET 用于众所周知的用途。 TrafficMonitor：网速、CPU、内存显示工具官网：zhongyang219&#x2F;TrafficMonitor: 这是一个用于显示当前网速、CPU及内存利用率的桌面悬浮窗软件，并支持任务栏显示，支持更换皮肤。 (github.com) 可在任务栏显示CPU、内存占用率和网速，也可以用悬浮窗显示，不过不如任务栏简洁。 Core Temp：CPU温度显示官网：Core Temp (alcpu.com) 任务栏托盘区显示，可精确到每个核心。 CPU-Z：CPU等硬件信息查询官网：CPU-Z | Softwares | CPUID 之前想买内存，用来查看内存时钟频率。也有显卡信息。 二、媒体类FSCapture：超级好用的截图工具官网：FastStone Screen Capture - The Best Screen Capture Software 非常小巧，还支持滚动截图，没见过比他更好用的。 PowerToys：取色器官网：microsoft&#x2F;PowerToys: Windows system utilities to maximize productivity (github.com) 微软官方的一款小工具，之前做UI的时候拿它来取色。还有其他功能，没有试过。 TopMost：窗口保持最前工具下载地址：Window TopMost Control v1.2 (sordum.org) 用浏览器看F1直播的时候，可以用这个工具让窗口保持最前，边看直播边敲代码。 Bandicut：视频剪辑、拼接工具官网：视频无损分割和拼接工具 - Bandicut（班迪剪辑）官网 (bandicam.cn) 如果只需要剪辑和拼接这两个操作的话，这个软件足够用了。 三、文献阅读类QTranslate：划词翻译官网：QTranslate - Home (quest-app.appspot.com) CopyTranslator：另一款复制翻译软件官网：CopyTranslator 四、游戏类Steam账户快速切换下载：Steam账户快速切换 V1.4 – Dogfight360","tags":[{"name":"软件","slug":"软件","permalink":"https://starman-swa.github.io/tags/%E8%BD%AF%E4%BB%B6/"}],"categories":[{"name":"软件","slug":"软件","permalink":"https://starman-swa.github.io/categories/%E8%BD%AF%E4%BB%B6/"}]},{"title":"记一次几乎踩了所有坑的Ubuntu双系统安装","date":"2021-01-14T17:20:37.000Z","path":"wiki/记一次几乎踩了所有坑的Ubuntu双系统安装/","text":"前言我的破本本用虚拟机跑Linux实在是顶不住，于是我昨天晚上一时兴起，想要给笔记本装 Windows 10 + Ubuntu 20.04 LTS 双系统。我的笔记本是UEFI引导，128GB SSD + 1TB机械硬盘，分区表格式都是GPT，Windows 10装在SSD上，计划在机械硬盘上分出128GB装Ubuntu（至于为什么才分这么点，显然是因为1T的硬盘几乎快被游戏填满了，逃）。 要么是我电脑的硬件兼容性太差，要么是我运气不佳，这次安装我居然步步踩坑，从昨天晚上折腾到今天晚上才把所有问题解决。这篇文章记录了我踩坑的全过程，仅供参考，切勿当作教程使用。 一、安装过程首先进行分区，我参考网上一篇教程，在SSD上划分出200M作为EFI引导分区，然后在机械硬盘上划分出128GiB空间作为Ubuntu主分区（注意：划分过程需要耐心等待，印象中花费了超过半个小时）。为了方便随后的安装过程中根据分区大小和位置找分区，我把分区结果拍了下来。 然后就可以使用U盘启动Ubuntu安装程序了：我从官网上下载了Ubuntu 20.04 LTS镜像，刻录到U盘当中。进UEFI BIOS（以下简称BIOS）把安全启动关闭，把U盘启动优先级调为最高，进入Ubuntu安装向导。 坑1. 安装向导卡住此时，第一个坑来了。在选择”正常安装“和”最小安装“的界面，我点击继续后卡住不动了。 解决方法是：在进入安装向导之前的grub菜单处按e编辑启动选项，将quiet splash ---改为quiet splash nomodeset，即增加nomodeset启动选项。nomodeset的含义如下： The newest kernels have moved the video mode setting into the kernel. So all the programming of the hardware specific clock rates and registers on the video card happen in the kernel rather than in the X driver when the X server starts.. This makes it possible to have high resolution nice looking splash (boot) screens and flicker free transitions from boot splash to login screen. Unfortunately, on some cards this doesnt work properly and you end up with a black screen. Adding the nomodeset parameter instructs the kernel to not load video drivers and use BIOS modes instead until X is loaded. 大意为，在新版的kernels当中，加载视频驱动的工作从原本的在加载图形化服务时进行，改为在加载kernel的时候就进行了，而部分显卡不兼容这一设定，可以用nomodeset选项改回原来的模式。 继续进行安装向导，安装方式选择“其他”，手动进行分区。我将128GiB的空间划分为swap、&#x2F;和&#x2F;home三个分区，其中swap分区的大小参照Ubuntu官网划分为11GB，剩下的按照1:3划分给&#x2F;和&#x2F;home。swap分区作为虚拟内存的一部分，Ubuntu官网的推荐值为：如果使用休眠功能，最小值不小于RAM，否则不小于sqrt(RAM)；其最大值不应超过RAM的两倍。此外，在分区界面，我将启动盘设置为SSD上分出来的那200M。分区完成，进行后续的设置后就完成安装了（由于还未设置代理，安装过程中我skip了需要下载的内容）。 坑2. 开机后直接进入Windows 10但是当我兴冲冲地重启电脑后发现：根本没有出现操作系统选择列表，开机后同原本一样直接进入Windows 10，第二个坑来了。 在Windows 10自带的磁盘管理页面中，我能看到机械硬盘上128GiB的空间被划为三个部分，同时SSD上那200M由空闲状态变为EFI系统文件状态，因此分区没有问题。会不会是引导的问题？我使用启动盘中的Try Ubuntu功能进入Ubuntu试用版，使用以下指令安装并运行了引导修复工具： 123sudo add-apt-repository ppa:yannubuntu/boot-repair -ysudo apt-get updatesudo apt-get install boot-repair -y 修复完成后弹出以下窗口： 按照第一句话，我应该将在BIOS当中把Ubuntu引导文件加入到启动项当中，但是我的BIOS并没有添加自定义启动项的功能。按照第二句话，我应该把Ubuntu启动项设置到Windows前面，但是我并没有在BIOS的启动选项当中看到Ubuntu和Windows，只有一个笼统的“操作系统的启动管理员”。因此我按照第三句话，在Windows命令行中将启动路径设置为Ubuntu的引导文件，没有效果。 我翻遍了BIOS，尝试了包括清除安全启动key和设置密码之内的多种方法都没有找到添加启动项的地方，正当我不知道应该如何继续时，我发现了启动项“操作系统的启动管理员”左边的小箭头。。。原来这个选项是可以细分的，按Enter果然弹出了Windows和Ubuntu两个启动项。这可能是我整个安装过程中犯过的最蠢的错误：对自己电脑的BIOS操作不熟悉。我将Ubuntu启动项设置到Windows前面之后，果然不再进入Windows了，第二个坑解决。 坑3. 开机后进入grub命令行第二个坑一解决，第三个坑随之而来：开机后进入的是grub命令行界面而不是grub菜单界面。我依然怀疑是引导出了问题，因此插入U盘，选择擦除旧系统再安装Ubuntu的选项重装系统。由于对引导缺乏认识，我也不清楚之前的引导是否正确安装，因此这次我选择让安装程序自动擦除旧系统后自动分区并安装。结果还是一样，依旧是开机后进入grub命令行。此时我再次查看Windows 10的磁盘管理，发现swap、&#x2F;、&#x2F;home的分区大小几乎没有改变，但是在机械硬盘上增加了一个EFI引导分区，且SSD上原来分配的200M也还在。 在grub命令行输入以下指令进入grub菜单： 1234567ls# 此时会显示磁盘列表ls 磁盘编号/boot/grub # 对所有磁盘编号尝试此指令，直至提示找到文件set root=找到文件的磁盘编号set prefix=找到文件的磁盘编号/boot/grubinsmod normalnormal 此时终于能进入grub菜单，选择Ubuntu系统。 坑4. Ubuntu系统只有鼠标紧接着第四个坑又来了：Ubuntu系统进入后，只有鼠标和背景，没有图标，无法进行任何操作。 经过尝试，解决方法是使用安全模式进入Ubuntu，修改&#x2F;etc&#x2F;default&#x2F;grub文件中的quiet splash改为quiet splash nomodeset，然后执行sudo update-grub指令更新grub。居然还是同样的问题，只不过这个指令如果在grub菜单中按e修改是一次性的，只有修改&#x2F;etc&#x2F;default&#x2F;grub文件才能永久生效。 踩完了四个坑，终于能正常进入Ubuntu了。不过，一进入系统，我就明显感觉屏幕非常暗。尝试笔记本的亮度调节功能键，无效；进入Ubuntu设置，居然找不到调节亮度的地方！我决定先配置代理，能够浏览Google之后再来解决亮度的问题。 顺利进入Ubuntu后，我使用df -lh和fdisk -l指令查看分区情况，发现&#x2F;boot&#x2F;efi被挂载在Windows 10的EFI引导分区上。此时，SSD上我划分出来的200M是闲置的，于是我使用Windows 10的DiskGenius软件将200M合并回Windows 10的C盘。至此，Ubuntu系统可以算是顺利安装完成。 二、配置代理我使用的代理工具是Clash。从Github仓库下载Clash的Release版本，解压后获得可执行文件。我存放在&#x2F;opt&#x2F;clash文件夹当中。第一次运行Clash会自动生成配置文件config.yaml和IP库文件Country.mmdb，文件存放路径为~/.config/clash。我将自己的config.yaml和Country.mmdb覆盖~/.config/clash目录中的文件，Clash即可正常运行。可在浏览器中输入clash.razord.top进入Clash的Web界面。 1. GNOME代理进入系统设置-网络-网络代理，模式设置为手动，填入相应的IP和端口号即可。此时，Firefox可以访问Google。 2. 终端代理和开机启动在系统设置当中配置代理只能让GNOME应用使用，而终端程序还要单独配置。配置方法十分简单，只需设置两个环境变量： 12export http_proxy=http://127.0.0.1:7890export https_proxy=http://127.0.0.1:7890 此时在非root账户当中可以使用wget google.com指令获取谷歌主页，然而在root账户中还不行，因为进入root账户时默认不会保存环境变量的值，解决方法是在&#x2F;etc&#x2F;sudoers中加入： 1Defaults env_keep += &quot;http_proxy https_proxy no_proxy&quot; 再来配置开机启动，开机启动首先需要以下shell脚本： 12345#!/bin/bashgsettings set org.gnome.system.proxy mode &#x27;manual&#x27; # ubuntu网络模式配置为手动cd /opt/clash # 切换到Clash的目录./clash -d /opt/clash &amp; # 在后台执行clash客户端echo &quot;Clash started!&quot; # 启动成功的提示 -d后面的路径设置为存放config.yaml和Country.mmdb的路径，&amp;表示后台运行。 将上述脚本连同设置两个环境变量的指令一同添加到~&#x2F;.profile文件当中，即可实现登陆当前账户时自动运行Clash并设置系统代理。由于&#x2F;etc&#x2F;sudoers文件也进行了修改，root账户也能够走代理。 三、无法设置亮度再回过头来解决亮度的问题，我先后尝试过以下几种方法： 1. 修改grub在&#x2F;etc&#x2F;default&#x2F;grub中设置以下参数并更新grub： 1GRUB_CMDLINE_LINUX=&quot;acpi_backlight=vendor&quot; 失败。 2. 使用亮度调节工具我先后尝试了brightness-controller和brightness-controller-simple两款工具，均失败。 3. 修改亮度文件与亮度有关的文件存放在&#x2F;sys&#x2F;class&#x2F;backlight文件夹中，然而，我的这个文件夹是空的，该方法失败。 4. 更新驱动一开始我使用这条指令更新驱动： 1sudo ubuntu-drivers autoinstall 然而不仅没有效果，因为这条指令为我安装了新版本的内核，使系统多内核共存，我还无法进入系统。我只能手动选择内核版本，设置为旧版系统启动，然后删除新版本。几个小时后，我阴差阳错地在“应用-软件和更新-附加驱动“当中看到了Nvidia显卡的驱动选择列表。默认选择的是开源驱动，我将其改为最新版的专用的、tested的驱动。 驱动更新后，重启电脑，居然又进不去系统了，提示”unable to bind the codec”。解决方法为：将&#x2F;etc&#x2F;default&#x2F;grub文件中的quite、slash、nomodeset三个参数都删除。quiet splash的含义如下： The splash (which eventually ends up in your &#x2F;boot&#x2F;grub&#x2F;grub.cfg ) causes the splash screen to be shown. At the same time you want the boot process to be quiet, as otherwise all kinds of messages would disrupt that splash screen. Although specified in GRUB these are kernel parameters influencing the loading of the kernel or its modules, not something that changes GRUB behaviour. The significant part from GRUB_CMDLINE_LINUX_DEFAULT is CMDLINE_LINUX. 光看说明我也不太明白，不过三个参数均删除之后确实可以进入系统，而且由于更新了驱动，亮度调节的滑块也出现了。Fn功能键也能正常调节亮度。 四、扬声器无声我写这篇博客写到一半时，突然想听歌，于是又发现了另外一个问题：扬声器之前有声音的，现在没有了。好家伙，连写博客都不能让我好好写。我运行自带的alsamixer工具发现，Headphone音量被设置为0，只需设置成100即可恢复正常。我怀疑是显卡驱动更新的时候更改的。 五、无法挂起在挂起状态按任意键唤醒之后，屏幕左上角会显示一个光标，然后卡在这个页面。尝试网上的教程安装laptop-mode-tools也无法解决，最后发现将显卡驱动降级即可。我室友的Surface Book也有同样的问题，但是它的核显支持的驱动较少，无法用这个方法解决。 六、总结这次安装踩的坑是真的多，不过我的第一反应是想用这篇博客记录下这个过程，而不是放弃。可能，这就是Linux的魅力吧。 生命不止，折腾不息。","tags":[{"name":"Linux","slug":"Linux","permalink":"https://starman-swa.github.io/tags/Linux/"}],"categories":[{"name":"Linux","slug":"Linux","permalink":"https://starman-swa.github.io/categories/Linux/"}]},{"title":"两道求最大面积的题目在解法上的不同","date":"2021-01-01T13:18:59.000Z","path":"wiki/两道求最大面积的题目在解法上的不同/","text":"今天发现两道看似十分相似但实际上有很大不同的题目，差点转不过弯来，分别是LeetCode 11 盛最多水的容器和LeetCode 84 柱状图中最大的矩形。 LeetCode 11 盛最多水的容器 给你 n 个非负整数 a1，a2，…，an，每个数代表坐标中的一个点 (i, ai) 。在坐标内画 n 条垂直线，垂直线 i 的两个端点分别为 (i, ai) 和 (i, 0) 。找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。 说明：你不能倾斜容器。 LeetCode 84 柱状图中最大的矩形 给定 n 个非负整数，用来表示柱状图中各个柱子的高度。每个柱子彼此相邻，且宽度为 1 。 求在该柱状图中，能够勾勒出来的矩形的最大面积。 我先写了84题，再回过头写11题时，以为两道题的区别就是柱状图和“挡板”的区别，还是用单调栈的方法，只需在求面积的时候做一点小修改即可。 先看84题。从左往右遍历柱状图的每一个柱形，若当前遍历到的柱形比上一个柱形高，则无法确定以上一个柱形的高为高的最大矩形面积，因为矩形可以越过当前柱形，一直延伸到右边，而右边的情况还不知道；反之，若当前遍历到的柱形比上一个柱形低，则以上一个柱形的高为高的矩形肯定无法越过当前柱形，又因为其左侧所有柱形已经遍历过了，所以矩形能够延伸到的左右两边的极限都可以确定，以上一个柱形的高为高的最大矩形面积也确定下来了。实际上，以当前柱形左侧的所有比当前柱形高的柱形的高为高的最大矩形面积都可以确定下来了。上述算法可以通过栈实现，栈中依次存储所有以第i个柱形为高的矩形的最大面积还未确定时的i值。 解决了第84题，我把代码套到第11题的时候发现无论我怎么修改边界条件，得出来的结果与答案都相去甚远。再次读题目的时候发现两道题有一个很大的不同：在第11题中，若确定了左右边界i、j，则所得矩形的高为min{height[i], height[j]}，换言之，水可以漫过挡板i、j中间的挡板；但在第84题中，所得矩形的高还受柱形i、j中间的柱形的限制，其值为min{height[i], height[i + 1], …, height[j - 1], height[j]}，换言之，柱形相当于容器，水不能超出容器，而且水的形状必须是矩形，可以将其理解为“冰块”。 因此，第11题只要确定了左右边界i、j，就可以确定矩形的面积，故遍历时使用双指针即可。","tags":[{"name":"单调栈","slug":"单调栈","permalink":"https://starman-swa.github.io/tags/%E5%8D%95%E8%B0%83%E6%A0%88/"},{"name":"双指针","slug":"双指针","permalink":"https://starman-swa.github.io/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"}],"categories":[{"name":"算法","slug":"算法","permalink":"https://starman-swa.github.io/categories/%E7%AE%97%E6%B3%95/"}]},{"title":"区间调度问题","date":"2020-12-28T14:58:17.000Z","path":"wiki/区间调度问题/","text":"一、区间不相交问题 给出N个开区间(start, end)，从中选择尽可能多的区间，使得这些区间两两不相交。 解决思路是将区间集合S中的所有区间按照end值从小到大的顺序进行排序，然后执行下列步骤： 从区间集合S中选取end值最小的区间i，将i加入区间集合T。 寻找与i相交的所有区间，将这些区间从集合S中删除。 若S非空，跳转到步骤1。 区间T即为所求。 证明思路可以考虑反证法：假设某一次选择的i的end值并不是集合S中最小的，如果存在与区间i相交且end值更小的区间i’，则选择i’所移除的区间数不会大于选择i所移除的区间数，此时选取end值更小的i’会使局部结果更优。 实现如下： 123456789101112131415161718192021222324static bool cmp(vector&lt;int&gt;&amp; a, vector&lt;int&gt;&amp; b)&#123; return a[1] &lt; b[1];&#125;int mostDisjointIntervals(vector&lt;vector&lt;int&gt;&gt;&amp; intervals)&#123; if (intervals.empty()) return 0; sort(intervals.begin(), intervals.end(), cmp); int count = 0; int i = 0; while (i &lt; intervals.size()) &#123; int j = i + 1; // 找到第一个不与intervals[i]相交的区间intervals[j] while (j &lt; intervals.size() &amp;&amp; intervals[j][0] &lt; intervals[i][1] ) ++j; ++count; i = j; &#125; return count;&#125; 二、应用1：LeetCode 435 无重叠区间 给定一个区间的集合，找到需要移除区间的最小数量，使剩余区间互不重叠。 移除的最小区间数量就是区间总数减去剩余的最大区间数量。 123int eraseOverlapIntervals(vector&lt;vector&lt;int&gt;&gt;&amp; intervals) &#123; return intervals.size() - mostDisjointIntervals(intervals);&#125; 三、应用2：LeetCode 452 用最少数量的箭引爆气球 在二维空间中有许多球形的气球。对于每个气球，提供的输入是水平方向上，气球直径的开始和结束坐标。由于它是水平的，所以纵坐标并不重要，因此只要知道开始和结束的横坐标就足够了。开始坐标总是小于结束坐标。 一支弓箭可以沿着 x 轴从不同点完全垂直地射出。在坐标 x 处射出一支箭，若有一个气球的直径的开始和结束坐标为 xstart，xend， 且满足 xstart ≤ x ≤ xend，则该气球会被引爆。可以射出的弓箭的数量没有限制。 弓箭一旦被射出之后，可以无限地前进。我们想找到使得所有气球全部被引爆，所需的弓箭的最小数量。 给你一个数组 points ，其中 points [i] &#x3D; [xstart,xend] ，返回引爆所有气球所必须射出的最小弓箭数。 在区间不相交问题中，每当选取一个区间时，与其相交的区间也会被移除。这相当于在本问题中，每射爆一个气球，与其相重叠的气球也会被射爆。因此两个问题是等价的，可以套用前面的代码，只不过本题中的区间是闭区间而不是开区间，需要修改边界条件。 12345678910111213int mostDisjointIntervals(vector&lt;vector&lt;int&gt;&gt;&amp; intervals)&#123; ... while (i &lt; intervals.size()) &#123; ... // 将小于号改为小于等于号 while (j &lt; intervals.size() &amp;&amp; intervals[j][0] &lt;= intervals[i][1] ) ++j; ... &#125; ...&#125; 四、变形1：LeetCode 56 合并区间 给出一个区间的集合，请合并所有重叠的区间。 本题仍是与区间重叠相关的问题，但是与上面三题有一点不同。上面三题的重叠区间是以某一个区间为参照的，也就是说所有的区间都必须与某一个特定的区间重叠。但是这一题不需要，对于所要合并的区间集合中的每一个区间，只需要与集合中的任意一个区间重叠即可。 本题的算法核心仍是贪心，但是需要做出一点调整：对区间集合使用字典排序，即先比较start，按照start升序排列，若start值相同，再按end升序排列。这样排序的目的是使所有能够进行合并的区间相邻。排序后，从前往后遍历区间，将尽可能多的相邻的重叠区间合并成一个大区间。对于每个合并后的大区间，其start值就是最左侧的小区间的start，其end值是所有小区间当中end值最大的那个。故在遍历期间，需要维护变量maxEnd存储end值的最大值。 题解如下，可见代码在上述三题的基础上修改了比较函数、内层循环的条件以及增加了maxEnd变量的维护： 123456789101112131415161718192021222324252627282930313233343536static bool cmp(vector&lt;int&gt;&amp; a, vector&lt;int&gt;&amp; b)&#123; if (a[0] &gt; b[0]) return false; else if (a[0] &lt; b[0]) return true; else if (a[1] &lt; b[1]) return true; return false;&#125;vector&lt;vector&lt;int&gt;&gt; merge(vector&lt;vector&lt;int&gt;&gt;&amp; intervals)&#123; vector&lt;vector&lt;int&gt;&gt; ans; if (intervals.empty()) return ans; sort(intervals.begin(), intervals.end(), cmp); int i = 0; while (i &lt; intervals.size()) &#123; int maxEnd = intervals[i][1]; int j = i + 1; // 找到第一个不与intervals[i]相交的区间intervals[j] while (j &lt; intervals.size() &amp;&amp; intervals[j][0] &lt;= maxEnd) &#123; if (intervals[j][1] &gt; maxEnd) maxEnd = intervals[j][1]; ++j; &#125; ans.push_back(vector&lt;int&gt; &#123;intervals[i][0], maxEnd&#125;); i = j; &#125; return ans;&#125; 五、变形2：LeetCode 57 插入区间 给出一个无重叠的 ，按照区间起始端点排序的区间列表。 在列表中插入一个新的区间，你需要确保列表中的区间仍然有序且不重叠（如果有必要的话，可以合并区间）。 这道题的难度为“困难”，但是相比之前的几道题目其实反而不需要用到什么特别的算法，只需从左到右遍历区间集合，找到新区间的插入位置并进行（可能的）合并操作。题目给的区间集合是无重叠的，因此省去了存储maxEnd的步骤，只需考虑边界条件进行适当的分类讨论即可。我的代码较为复杂，还可以进一步简化。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849vector&lt;vector&lt;int&gt;&gt; insert(vector&lt;vector&lt;int&gt;&gt;&amp; intervals, vector&lt;int&gt;&amp; newInterval)&#123; vector&lt;vector&lt;int&gt;&gt; ans; if (intervals.empty()) &#123; ans.push_back(newInterval); return ans; &#125; bool inserted = false; int i = 0; while (i &lt; intervals.size()) &#123; if (!inserted) &#123; if (newInterval[0] &gt; intervals[i][1]) ans.push_back(intervals[i++]); else if (newInterval[1] &gt;= intervals[i][0]) &#123; int j = i + 1; while (j &lt; intervals.size() &amp;&amp; intervals[j][0] &lt;= newInterval[1]) ++j; int newStart = min(newInterval[0], intervals[i][0]); if (j == i + 1) ans.push_back(&#123;newStart, max(intervals[i][1], newInterval[1])&#125;); else &#123; ans.push_back(&#123;newStart, max(intervals[j - 1][1], newInterval[1])&#125;); &#125; inserted = true; i = j; &#125; else &#123; ans.push_back(newInterval); ans.push_back(intervals[i++]); inserted = true; &#125; &#125; else &#123; ans.push_back(intervals[i++]); &#125; &#125; if (!inserted) ans.push_back(newInterval); return ans;&#125;","tags":[{"name":"贪心","slug":"贪心","permalink":"https://starman-swa.github.io/tags/%E8%B4%AA%E5%BF%83/"}],"categories":[{"name":"算法","slug":"算法","permalink":"https://starman-swa.github.io/categories/%E7%AE%97%E6%B3%95/"}]}]}